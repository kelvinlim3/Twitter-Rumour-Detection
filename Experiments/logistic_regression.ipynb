{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_X_train = joblib.load('Processed Data/pp_train_sources.data')\n",
    "source_X_dev = joblib.load('Processed Data/pp_dev_sources.data')\n",
    "source_X_test= joblib.load('Processed Data/pp_test_sources.data')\n",
    "\n",
    "#replies_X_train = joblib.load('Processed Data/pp_train_replies.data')\n",
    "#replies_X_dev= joblib.load('Processed Data/pp_dev_replies.data')\n",
    "#replies_X_test = joblib.load('Processed Data/pp_test_replies.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating Labels from Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_y_train = source_X_train.pop('class')\n",
    "source_y_dev = source_X_dev.pop('class')\n",
    "source_X_test.drop(['class'], axis=1, inplace=True)\n",
    "\n",
    "#replies_y_train = replies_X_train.pop('source class')\n",
    "#replies_y_dev = replies_X_dev.pop('source class')\n",
    "#replies_X_test.drop(['source class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_val_accuracy(preds, source_y_dev=source_y_dev):\n",
    "    correct = 0\n",
    "    for id, pred in enumerate(preds):\n",
    "        if pred == source_y_dev[id]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_c = 0\n",
    "best_pred = []\n",
    "for c in np.arange(0.1, 2, 0.2):\n",
    "    lr_classif = LogisticRegression(C=c, max_iter=1000)\n",
    "\n",
    "    lr_classif.fit(source_X_train, source_y_train)\n",
    "    dev_pred = lr_classif.predict(source_X_dev)\n",
    "    acc = check_val_accuracy(dev_pred)\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_c = c\n",
    "        best_pred = dev_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214953271028037"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000000000000001"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.93      0.96      0.95       420\n",
      "      rumour       0.85      0.74      0.79       115\n",
      "\n",
      "    accuracy                           0.92       535\n",
      "   macro avg       0.89      0.85      0.87       535\n",
      "weighted avg       0.91      0.92      0.91       535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(source_y_dev, dev_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_accuracy = 0\n",
    "best_c = 0\n",
    "best_pred = []\n",
    "for c in np.arange(0.1, 3, 0.2):\n",
    "    classif = SVC(C=c)\n",
    "\n",
    "    classif.fit(source_X_train, source_y_train)\n",
    "    dev_pred = classif.predict(source_X_dev)\n",
    "    acc = check_val_accuracy(dev_pred)\n",
    "\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_c = c\n",
    "        best_pred = dev_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289719626168225"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000000000000004"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.94      0.98      0.96       420\n",
      "      rumour       0.90      0.76      0.82       115\n",
      "\n",
      "    accuracy                           0.93       535\n",
      "   macro avg       0.92      0.87      0.89       535\n",
      "weighted avg       0.93      0.93      0.93       535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(source_y_dev, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = classif.predict(source_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "..        ...\n",
       "553         0\n",
       "554         1\n",
       "555         1\n",
       "556         0\n",
       "557         0\n",
       "\n",
       "[558 rows x 1 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_pred, columns=[\"Predicted\"])\n",
    "pred_df.name = 'id'\n",
    "pred_df.loc[pred_df['Predicted'] == 'nonrumour'] = 0\n",
    "pred_df.loc[pred_df['Predicted'] == 'rumour'] = 1\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('predictions2.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "493206a705d8b4cacbc39cadb7e0a8b8105bda776bb0398dd20689231958a4bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('NeuralNetwork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
