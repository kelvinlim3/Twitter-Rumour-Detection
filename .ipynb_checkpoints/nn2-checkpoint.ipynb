{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4b6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "\n",
    "api_key = \"aJTgi4d1H1zmQNkQuHeualNhP\"\n",
    "api_secrets = \"yPFdp2Bbib25r1iPQCqBuPq8B9UzoJbIdpv1jgzEZFEg1eJl6X\"\n",
    "access_token = \"1409382627124019204-oPpzVGuCwyFfQTfoocFhgHi68whhog\"\n",
    "access_secret = \"esgwpH5gnRfNB0SpiHkO52mZSI5VKKnn8SG2pafEnzj2b\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "\n",
    "TWEET_OBJECT_PATH = 'tweet-objects/'\n",
    "\n",
    " \n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed Authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec52f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(filename):\n",
    "    file = open(filename)\n",
    "    threads = file.readlines()\n",
    "    file.close()\n",
    "    return [thread.replace('\\n', '').split(',') for thread in threads]\n",
    "\n",
    "def get_labels(filename):    \n",
    "    file = open(filename)\n",
    "    labels = file.readlines()\n",
    "    file.close()\n",
    "    return [label.replace('\\n', '') for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c63e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1250219300389974016', '1250219116993974272', '1250219437027766273', '1250219620939657216', '1250219777185873922', '1250219894429208577', '1250219998842216448', '1250220115762667520', '1250220272306638848', '1250220389323526146', '1250220527005753344', '1250220791544705025', '1250220987238383616', '1250221140603047937', '1250221275827470336', '1250221402822545410']\n",
      "\n",
      "nonrumour\n"
     ]
    }
   ],
   "source": [
    "train_ids = get_ids('train.data.txt')\n",
    "train_labels = get_labels('train.label.txt')\n",
    "\n",
    "dev_ids = get_ids('dev.data.txt')\n",
    "dev_labels = get_labels('dev.label.txt')\n",
    "\n",
    "test_ids = get_ids('test.data.txt')\n",
    "\n",
    "print(train_ids[0])\n",
    "print()\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8099fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_ids = [id_ for id_list in train_ids for id_ in id_list]\n",
    "flat_dev_ids = [id_ for id_list in dev_ids for id_ in id_list]\n",
    "flat_test_ids = [id_ for id_list in test_ids for id_ in id_list]\n",
    "\n",
    "unique_ids = list(set(flat_train_ids + flat_dev_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b25b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet id: full text of tweet if found by api, otherwise text from tweet-objects\n",
    "tweets_dict = {}\n",
    "\n",
    "def get_train_tweets_from_api(ids):\n",
    "    for i in range(0, len(ids), 100):\n",
    "        split = ids[i:i+100]\n",
    "        for tweet in api.lookup_statuses(split, tweet_mode='extended'):\n",
    "            tweets_dict[tweet.id_str] = {}\n",
    "            tweets_dict[tweet.id_str]['text'] = tweet.full_text\n",
    "            tweets_dict[tweet.id_str]['user'] = tweet.user.screen_name\n",
    "            tweets_dict[tweet.id_str]['verified'] = tweet.user.verified\n",
    "            tweets_dict[tweet.id_str]['likes'] = tweet.favorite_count\n",
    "            tweets_dict[tweet.id_str]['retweets'] = tweet.retweet_count\n",
    "            \n",
    "def get_test_tweets(ids):\n",
    "    for id_ in ids:\n",
    "        file = open(f'tweet-objects/{id_}.json')\n",
    "        tweet_object = json.load(file)\n",
    "        file.close()\n",
    "        id_str = tweet_object['id_str']\n",
    "        tweets_dict[id_str] = {}\n",
    "        tweets_dict[id_str]['text'] = tweet_object['text']\n",
    "        tweets_dict[id_str]['user'] = tweet_object['user']['screen_name']\n",
    "        tweets_dict[id_str]['verified'] = tweet_object['user']['verified']\n",
    "        tweets_dict[id_str]['likes'] = tweet_object['favorite_count']\n",
    "        tweets_dict[id_str]['retweets'] = tweet_object['retweet_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd82c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_train_tweets_from_api(unique_ids)\n",
    "get_test_tweets(flat_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725f116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = []\n",
    "tweet_user = []\n",
    "tweet_verified = []\n",
    "tweet_likes = []\n",
    "tweet_retweets = []\n",
    "\n",
    "for tweet_id in tweets_dict.keys():\n",
    "    tweet_text.append(tweets_dict[tweet_id]['text'])\n",
    "    tweet_user.append(tweets_dict[tweet_id]['user'])\n",
    "    tweet_verified.append(tweets_dict[tweet_id]['verified'])\n",
    "    tweet_likes.append(tweets_dict[tweet_id]['likes'])\n",
    "    tweet_retweets.append(tweets_dict[tweet_id]['retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abff3068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1254347829365092357</th>\n",
       "      <td>1254347829365092357</td>\n",
       "      <td>@Gasbymalony @CACCOT1 Everything to these peop...</td>\n",
       "      <td>Kaymania3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523565690725617664</th>\n",
       "      <td>523565690725617664</td>\n",
       "      <td>@davidgrelle so what if it is Wilson didn't do...</td>\n",
       "      <td>Jeffmw</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553603571200311296</th>\n",
       "      <td>553603571200311296</td>\n",
       "      <td>Yes!! üòéüëç RT ‚Äú@SkyNews: Hostage-taker in superm...</td>\n",
       "      <td>Gm4nHere</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521541390077943808</th>\n",
       "      <td>521541390077943808</td>\n",
       "      <td>@TMZ wow, this saga will not end well regardless.</td>\n",
       "      <td>22lunamint</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252683209390739456</th>\n",
       "      <td>1252683209390739456</td>\n",
       "      <td>ONS weekly deaths in London, UK, updated for w...</td>\n",
       "      <td>lenapatsa</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222929611232817159</th>\n",
       "      <td>1222929611232817159</td>\n",
       "      <td>@crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...</td>\n",
       "      <td>96incognito69</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222944075826884608</th>\n",
       "      <td>1222944075826884608</td>\n",
       "      <td>@WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...</td>\n",
       "      <td>ellenli_lxw</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324381215707139</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>Can CoVID-19 be caught from a person who has n...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324383396716546</th>\n",
       "      <td>1239324383396716546</td>\n",
       "      <td>However, many people with #COVID-19 experience...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324385707687938</th>\n",
       "      <td>1239324385707687938</td>\n",
       "      <td>@WHO is assessing ongoing research on the peri...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34130 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "1254347829365092357  1254347829365092357   \n",
       "523565690725617664    523565690725617664   \n",
       "553603571200311296    553603571200311296   \n",
       "521541390077943808    521541390077943808   \n",
       "1252683209390739456  1252683209390739456   \n",
       "...                                  ...   \n",
       "1222929611232817159  1222929611232817159   \n",
       "1222944075826884608  1222944075826884608   \n",
       "1239324381215707139  1239324381215707139   \n",
       "1239324383396716546  1239324383396716546   \n",
       "1239324385707687938  1239324385707687938   \n",
       "\n",
       "                                                                  text  \\\n",
       "1254347829365092357  @Gasbymalony @CACCOT1 Everything to these peop...   \n",
       "523565690725617664   @davidgrelle so what if it is Wilson didn't do...   \n",
       "553603571200311296   Yes!! üòéüëç RT ‚Äú@SkyNews: Hostage-taker in superm...   \n",
       "521541390077943808   @TMZ wow, this saga will not end well regardless.   \n",
       "1252683209390739456  ONS weekly deaths in London, UK, updated for w...   \n",
       "...                                                                ...   \n",
       "1222929611232817159  @crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...   \n",
       "1222944075826884608  @WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...   \n",
       "1239324381215707139  Can CoVID-19 be caught from a person who has n...   \n",
       "1239324383396716546  However, many people with #COVID-19 experience...   \n",
       "1239324385707687938  @WHO is assessing ongoing research on the peri...   \n",
       "\n",
       "                              user  verified  likes  retweets  \n",
       "1254347829365092357      Kaymania3     False      2         0  \n",
       "523565690725617664          Jeffmw     False      0         0  \n",
       "553603571200311296        Gm4nHere     False      0         0  \n",
       "521541390077943808      22lunamint     False      0         0  \n",
       "1252683209390739456      lenapatsa     False      4         1  \n",
       "...                            ...       ...    ...       ...  \n",
       "1222929611232817159  96incognito69     False      4         0  \n",
       "1222944075826884608    ellenli_lxw     False      1         0  \n",
       "1239324381215707139  mugabo_robert     False      1         1  \n",
       "1239324383396716546  mugabo_robert     False      1         1  \n",
       "1239324385707687938  mugabo_robert     False      1         1  \n",
       "\n",
       "[34130 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids_df = pd.DataFrame({'id': tweets_dict.keys(), \n",
    "                             'text': tweet_text, \n",
    "                             'user': tweet_user,\n",
    "                             'verified': tweet_verified,\n",
    "                             'likes': tweet_likes,\n",
    "                             'retweets': tweet_retweets},\n",
    "                              index=tweets_dict.keys())\n",
    "tweet_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17bfcf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mugabo_robert'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.get_status('1239324385707687938').user.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d3186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids_df.to_csv('tweets_id_text.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9681c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1254347829365092357</th>\n",
       "      <td>1254347829365092357</td>\n",
       "      <td>@Gasbymalony @CACCOT1 Everything to these peop...</td>\n",
       "      <td>Kaymania3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523565690725617664</th>\n",
       "      <td>523565690725617664</td>\n",
       "      <td>@davidgrelle so what if it is Wilson didn't do...</td>\n",
       "      <td>Jeffmw</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553603571200311296</th>\n",
       "      <td>553603571200311296</td>\n",
       "      <td>Yes!! üòéüëç RT ‚Äú@SkyNews: Hostage-taker in superm...</td>\n",
       "      <td>Gm4nHere</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521541390077943808</th>\n",
       "      <td>521541390077943808</td>\n",
       "      <td>@TMZ wow, this saga will not end well regardless.</td>\n",
       "      <td>22lunamint</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252683209390739456</th>\n",
       "      <td>1252683209390739456</td>\n",
       "      <td>ONS weekly deaths in London, UK, updated for w...</td>\n",
       "      <td>lenapatsa</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222929611232817159</th>\n",
       "      <td>1222929611232817159</td>\n",
       "      <td>@crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...</td>\n",
       "      <td>96incognito69</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222944075826884608</th>\n",
       "      <td>1222944075826884608</td>\n",
       "      <td>@WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...</td>\n",
       "      <td>ellenli_lxw</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324381215707139</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>Can CoVID-19 be caught from a person who has n...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324383396716546</th>\n",
       "      <td>1239324383396716546</td>\n",
       "      <td>However, many people with #COVID-19 experience...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324385707687938</th>\n",
       "      <td>1239324385707687938</td>\n",
       "      <td>@WHO is assessing ongoing research on the peri...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34130 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "1254347829365092357  1254347829365092357   \n",
       "523565690725617664    523565690725617664   \n",
       "553603571200311296    553603571200311296   \n",
       "521541390077943808    521541390077943808   \n",
       "1252683209390739456  1252683209390739456   \n",
       "...                                  ...   \n",
       "1222929611232817159  1222929611232817159   \n",
       "1222944075826884608  1222944075826884608   \n",
       "1239324381215707139  1239324381215707139   \n",
       "1239324383396716546  1239324383396716546   \n",
       "1239324385707687938  1239324385707687938   \n",
       "\n",
       "                                                                  text  \\\n",
       "1254347829365092357  @Gasbymalony @CACCOT1 Everything to these peop...   \n",
       "523565690725617664   @davidgrelle so what if it is Wilson didn't do...   \n",
       "553603571200311296   Yes!! üòéüëç RT ‚Äú@SkyNews: Hostage-taker in superm...   \n",
       "521541390077943808   @TMZ wow, this saga will not end well regardless.   \n",
       "1252683209390739456  ONS weekly deaths in London, UK, updated for w...   \n",
       "...                                                                ...   \n",
       "1222929611232817159  @crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...   \n",
       "1222944075826884608  @WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...   \n",
       "1239324381215707139  Can CoVID-19 be caught from a person who has n...   \n",
       "1239324383396716546  However, many people with #COVID-19 experience...   \n",
       "1239324385707687938  @WHO is assessing ongoing research on the peri...   \n",
       "\n",
       "                              user  verified  likes  retweets  \n",
       "1254347829365092357      Kaymania3     False      2         0  \n",
       "523565690725617664          Jeffmw     False      0         0  \n",
       "553603571200311296        Gm4nHere     False      0         0  \n",
       "521541390077943808      22lunamint     False      0         0  \n",
       "1252683209390739456      lenapatsa     False      4         1  \n",
       "...                            ...       ...    ...       ...  \n",
       "1222929611232817159  96incognito69     False      4         0  \n",
       "1222944075826884608    ellenli_lxw     False      1         0  \n",
       "1239324381215707139  mugabo_robert     False      1         1  \n",
       "1239324383396716546  mugabo_robert     False      1         1  \n",
       "1239324385707687938  mugabo_robert     False      1         1  \n",
       "\n",
       "[34130 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids_df = pd.read_csv('tweets_id_text.csv', index_col=0) \n",
    "tweet_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c1930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    # rumour: 1, nonrumour: 0\n",
    "    if label == 'rumour':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def concatenate_tweets(source, reply_ids):\n",
    "    concat = source\n",
    "    \n",
    "    for id_ in reply_ids:\n",
    "        try:\n",
    "            tweet = tweet_ids_df.loc[int(id_), 'text'] # may throw key error\n",
    "            concat += ' ' + tweet\n",
    "        except:\n",
    "            continue\n",
    "    concat = concat.strip()\n",
    "    \n",
    "    return concat\n",
    "\n",
    "def create_dataframe(ids, labs, include_labels=True):\n",
    "    source_ids = []\n",
    "    reply_ids_list = []\n",
    "    concat_tweets = []\n",
    "    users = []\n",
    "    verified = []\n",
    "    likes = []\n",
    "    retweets = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        # add concatenation of source and reply tweets to concat_tweets\n",
    "        try:\n",
    "            source = tweet_ids_df.loc[int(ids[i][0]), 'text'] # may throw key error\n",
    "            if len(ids[i]) > 1:\n",
    "                concat = concatenate_tweets(source, ids[i][1:])\n",
    "            concat_tweets.append(concat)\n",
    "            users.append(tweet_ids_df.loc[int(ids[i][0]), 'user'])\n",
    "            verified.append(tweet_ids_df.loc[int(ids[i][0]), 'verified'])\n",
    "            likes.append(tweet_ids_df.loc[int(ids[i][0]), 'likes'])\n",
    "            retweets.append(tweet_ids_df.loc[int(ids[i][0]), 'retweets'])\n",
    "        except:\n",
    "            if include_labels:\n",
    "                continue # skip instance if source tweet is missing\n",
    "            else:\n",
    "                concat_tweets.append('')\n",
    "\n",
    "        # add id of source tweet to source_ids\n",
    "        source_ids.append(ids[i][0])\n",
    "\n",
    "        # add list of ids of reply tweets to reply_ids_list if there are replies\n",
    "        if len(ids[i]) > 1:\n",
    "            reply_ids_list.append(ids[i][1:])\n",
    "        else:\n",
    "            reply_ids_list.append([])              \n",
    "\n",
    "        if include_labels:\n",
    "            # add encoded label to labels (1 for rumour, 0 for nonrumour)\n",
    "            label = encode_label(labs[i])\n",
    "            labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame({'source_id': source_ids, \n",
    "                       'reply_ids': reply_ids_list,\n",
    "                       'concat_tweet': concat_tweets,\n",
    "                       'user': users, \n",
    "                       'verified': verified,\n",
    "                       'likes': likes,\n",
    "                       'retweets': retweets})\n",
    "    \n",
    "    if include_labels:\n",
    "        df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ef5ea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250219300389974016</td>\n",
       "      <td>[1250219116993974272, 1250219437027766273, 125...</td>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554886875303780352</td>\n",
       "      <td>[554894001946759168, 554959644125167617, 55492...</td>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237901309011021825</td>\n",
       "      <td>[1237901311439450112, 1239862502516760577]</td>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524958128392376320</td>\n",
       "      <td>[524961934064754688, 524959028061798401, 52495...</td>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239295488677085185</td>\n",
       "      <td>[1239562248990806016]</td>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id                                          reply_ids  \\\n",
       "0  1250219300389974016  [1250219116993974272, 1250219437027766273, 125...   \n",
       "1   554886875303780352  [554894001946759168, 554959644125167617, 55492...   \n",
       "2  1237901309011021825         [1237901311439450112, 1239862502516760577]   \n",
       "3   524958128392376320  [524961934064754688, 524959028061798401, 52495...   \n",
       "4  1239295488677085185                              [1239562248990806016]   \n",
       "\n",
       "                                        concat_tweet             user  \\\n",
       "0  5. Can regularly rinsing your nose with saline...        ucoptempe   \n",
       "1  French police chief killed himself after #Char...        Telegraph   \n",
       "2  Coronavirus disease (COVID-19) advice for the ...  kareem_alnakeeb   \n",
       "3  Ottawa police confirm that there were multiple...              WSJ   \n",
       "4  if the primary focus of a government isn't to ...     hoss_bossman   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0     False      0         0      0  \n",
       "1      True     43       184      1  \n",
       "2     False      3         1      0  \n",
       "3      True     23       119      0  \n",
       "4     False      6         1      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = create_dataframe(train_ids, train_labels)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b18993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>[1249011200068730880]</td>\n",
       "      <td>COVID-19 Fact:\\nAre hand dryers effective in k...</td>\n",
       "      <td>WeatherBug</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>[1270394169836568576, 1270502071175909376]</td>\n",
       "      <td>@atruchecks when can we expect the result of m...</td>\n",
       "      <td>ewart_lynne</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>[1235234904281165825, 1235234927937048577, 123...</td>\n",
       "      <td>How does COVID-19 spread? \\n\\nPeople can catch...</td>\n",
       "      <td>Agali_GCFR</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>[1248775858120097792]</td>\n",
       "      <td>every news outlet using headlines like,\\n\\n\"ar...</td>\n",
       "      <td>TuckyAalto</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>[523943560589361152, 524027059346370560, 53048...</td>\n",
       "      <td>Researcher @naskrecki on his encounter with a ...</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id                                          reply_ids  \\\n",
       "0  1249004694950817796                              [1249011200068730880]   \n",
       "1  1267552274819227649         [1270394169836568576, 1270502071175909376]   \n",
       "2  1235238334722699265  [1235234904281165825, 1235234927937048577, 123...   \n",
       "3  1248746792914546688                              [1248775858120097792]   \n",
       "4   523820806917603328  [523943560589361152, 524027059346370560, 53048...   \n",
       "\n",
       "                                        concat_tweet         user  verified  \\\n",
       "0  COVID-19 Fact:\\nAre hand dryers effective in k...   WeatherBug     False   \n",
       "1  @atruchecks when can we expect the result of m...  ewart_lynne     False   \n",
       "2  How does COVID-19 spread? \\n\\nPeople can catch...   Agali_GCFR     False   \n",
       "3  every news outlet using headlines like,\\n\\n\"ar...   TuckyAalto     False   \n",
       "4  Researcher @naskrecki on his encounter with a ...      Harvard      True   \n",
       "\n",
       "   likes  retweets  label  \n",
       "0      6         1      0  \n",
       "1      0         0      0  \n",
       "2      0         0      0  \n",
       "3     17         0      0  \n",
       "4     71       149      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_full_df = create_dataframe(dev_ids, dev_labels)\n",
    "dev_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd655731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>[1247355493988909056]</td>\n",
       "      <td>How Does COVID-19 Spread? https://t.co/TXHDeUp...</td>\n",
       "      <td>WCCO</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>[1251884146403815428, 1252033306100670464, 125...</td>\n",
       "      <td>@brain_warrior I hate to keep saying it, but C...</td>\n",
       "      <td>Kikasitsu</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>[1236050046950481922, 1236050331940855808]</td>\n",
       "      <td>Q. How are COVID-19 and influenza viruses diff...</td>\n",
       "      <td>CovidIreland</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>[1235584239497867275, 1235585067973578752, 123...</td>\n",
       "      <td>Una de les Q&amp;amp;A on coronaviruses de la p√†gi...</td>\n",
       "      <td>PerePuigUAB</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>[1258710626676899840, 1258711444075565058, 125...</td>\n",
       "      <td>@_truthpolitics We should absolutely blame the...</td>\n",
       "      <td>klarth</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>427944719612915712</td>\n",
       "      <td>[427960532981665792, 427949634032783360, 42794...</td>\n",
       "      <td>Ex-Marlboro man dies from smoking-related dise...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>531206167302012929</td>\n",
       "      <td>[531228826496679936, 531255748157005825, 53120...</td>\n",
       "      <td>Holy shit. Doritos flavored Mountain Dew.\\n\\nA...</td>\n",
       "      <td>Boogie2988</td>\n",
       "      <td>True</td>\n",
       "      <td>342</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>553099685888790528</td>\n",
       "      <td>[553640547282608128, 557627319322685441, 55310...</td>\n",
       "      <td>Banksy account joins cartoonists support for #...</td>\n",
       "      <td>ThePoke</td>\n",
       "      <td>True</td>\n",
       "      <td>230</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1222928724112396288</td>\n",
       "      <td>[1222922750546923521, 1222929006967869442, 122...</td>\n",
       "      <td>@DrTedros @WHOWPRO @WHOSEARO @WHO_Europe @paho...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>[1239324383396716546, 1239324385707687938]</td>\n",
       "      <td>Can CoVID-19 be caught from a person who has n...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source_id                                          reply_ids  \\\n",
       "0    1246482832316301319                              [1247355493988909056]   \n",
       "1    1252279738099433473  [1251884146403815428, 1252033306100670464, 125...   \n",
       "2    1236050255394877440         [1236050046950481922, 1236050331940855808]   \n",
       "3    1235582115900796928  [1235584239497867275, 1235585067973578752, 123...   \n",
       "4    1258787515592572928  [1258710626676899840, 1258711444075565058, 125...   \n",
       "..                   ...                                                ...   \n",
       "553   427944719612915712  [427960532981665792, 427949634032783360, 42794...   \n",
       "554   531206167302012929  [531228826496679936, 531255748157005825, 53120...   \n",
       "555   553099685888790528  [553640547282608128, 557627319322685441, 55310...   \n",
       "556  1222928724112396288  [1222922750546923521, 1222929006967869442, 122...   \n",
       "557  1239324381215707139         [1239324383396716546, 1239324385707687938]   \n",
       "\n",
       "                                          concat_tweet            user  \\\n",
       "0    How Does COVID-19 Spread? https://t.co/TXHDeUp...            WCCO   \n",
       "1    @brain_warrior I hate to keep saying it, but C...       Kikasitsu   \n",
       "2    Q. How are COVID-19 and influenza viruses diff...    CovidIreland   \n",
       "3    Una de les Q&amp;A on coronaviruses de la p√†gi...     PerePuigUAB   \n",
       "4    @_truthpolitics We should absolutely blame the...          klarth   \n",
       "..                                                 ...             ...   \n",
       "553  Ex-Marlboro man dies from smoking-related dise...  washingtonpost   \n",
       "554  Holy shit. Doritos flavored Mountain Dew.\\n\\nA...      Boogie2988   \n",
       "555  Banksy account joins cartoonists support for #...         ThePoke   \n",
       "556  @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe @paho...             WHO   \n",
       "557  Can CoVID-19 be caught from a person who has n...   mugabo_robert   \n",
       "\n",
       "     verified  likes  retweets  \n",
       "0        True      4         0  \n",
       "1       False      0         0  \n",
       "2       False      2         0  \n",
       "3       False      3         4  \n",
       "4       False      0         0  \n",
       "..        ...    ...       ...  \n",
       "553      True     26       139  \n",
       "554      True    342       181  \n",
       "555      True    230       350  \n",
       "556      True     47        19  \n",
       "557     False      1         1  \n",
       "\n",
       "[558 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_df = create_dataframe(test_ids, None, include_labels=False)\n",
    "test_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b24c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        concat_tweet             user  \\\n",
       "0  5. Can regularly rinsing your nose with saline...        ucoptempe   \n",
       "1  French police chief killed himself after #Char...        Telegraph   \n",
       "2  Coronavirus disease (COVID-19) advice for the ...  kareem_alnakeeb   \n",
       "3  Ottawa police confirm that there were multiple...              WSJ   \n",
       "4  if the primary focus of a government isn't to ...     hoss_bossman   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0     False      0         0      0  \n",
       "1      True     43       184      1  \n",
       "2     False      3         1      0  \n",
       "3      True     23       119      0  \n",
       "4     False      6         1      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "dev_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "test_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbf1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    preprocessed = df\n",
    "    text = list(preprocessed['concat_tweet'])\n",
    "    verified = list(preprocessed['verified'])\n",
    "    sentiment = []\n",
    "    for i in range(len(text)):\n",
    "        text[i] = \" \".join(filter(lambda x:x[0]!='@', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:4]!='http', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:4]!='&amp', text[i].split()))\n",
    "        text[i] = re.sub(r'[^a-zA-Z ]','',text[i])\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:1]!='Q', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:1]!='A', text[i].split()))\n",
    "        sentiment.append(TextBlob(text[i]).sentiment.polarity)\n",
    "    preprocessed['concat_tweet'] = text\n",
    "    for j in range(len(verified)):\n",
    "        if verified[j]:\n",
    "            verified[j] = 1\n",
    "        else:\n",
    "            verified[j] = 0\n",
    "    preprocessed['verified'] = verified\n",
    "    preprocessed.insert(1, 'sentiment',sentiment)\n",
    "    preprocessed.fillna('', inplace=True)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8329e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can regularly rinsing your nose with saline he...</td>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French police chief killed himself after Charl...</td>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease COVID advice for the publi...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the primary focus of a government isnt to a...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>It cannot be transmitted through goods manufac...</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>sattykrosse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Desperate Ted Cruz Claims Planned Parenthood S...</td>\n",
       "      <td>-0.191270</td>\n",
       "      <td>Bipartisanism</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Thoughts and prayers are not enough Pres Obama...</td>\n",
       "      <td>0.031427</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>Police have surrounded this building where the...</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>NBCNews</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>I can help am Socialism what is it and why do ...</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>rosierawle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           concat_tweet  sentiment  \\\n",
       "0     Can regularly rinsing your nose with saline he...   0.173437   \n",
       "1     French police chief killed himself after Charl...  -0.278125   \n",
       "2     Coronavirus disease COVID advice for the publi...   0.133333   \n",
       "3     Ottawa police confirm that there were multiple...   0.133333   \n",
       "4     if the primary focus of a government isnt to a...   0.400000   \n",
       "...                                                 ...        ...   \n",
       "1559  It cannot be transmitted through goods manufac...   0.040770   \n",
       "1560  Desperate Ted Cruz Claims Planned Parenthood S...  -0.191270   \n",
       "1561  Thoughts and prayers are not enough Pres Obama...   0.031427   \n",
       "1562  Police have surrounded this building where the...  -0.057692   \n",
       "1563  I can help am Socialism what is it and why do ...  -0.005323   \n",
       "\n",
       "                 user  verified  likes  retweets  label  \n",
       "0           ucoptempe         0      0         0      0  \n",
       "1           Telegraph         1     43       184      1  \n",
       "2     kareem_alnakeeb         0      3         1      0  \n",
       "3                 WSJ         1     23       119      0  \n",
       "4        hoss_bossman         0      6         1      0  \n",
       "...               ...       ...    ...       ...    ...  \n",
       "1559      sattykrosse         0      0         0      0  \n",
       "1560    Bipartisanism         1     56        76      1  \n",
       "1561              ABC         1    148       108      1  \n",
       "1562          NBCNews         1     63       176      0  \n",
       "1563       rosierawle         0      0         0      0  \n",
       "\n",
       "[1552 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = preprocess_df(train_full_df)\n",
    "train_full_df.drop_duplicates(subset=['concat_tweet'][0:100],inplace=True)\n",
    "\n",
    "dev_full_df = preprocess_df(dev_full_df)\n",
    "dev_full_df.drop_duplicates(subset=['concat_tweet'][0:100],inplace=True)\n",
    "\n",
    "test_full_df = preprocess_df(test_full_df)\n",
    "train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1e26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english')) #note: stopwords are all in lowercase\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def tokenize_df(df):\n",
    "    tokenized_df = df\n",
    "    tokenized_sentence = []\n",
    "    for _id, row in tokenized_df.iterrows():\n",
    "        text = row['concat_tweet']\n",
    "        # tokenize tweet\n",
    "        tokens = tt.tokenize(text)\n",
    "        # convert to lowercase\n",
    "        tokens = [tok.lower() for tok in tokens]\n",
    "        # remove stopwords\n",
    "        tokens = [tok for tok in tokens if tok not in stopwords]\n",
    "        # lemmatize\n",
    "        tokens = [lemmatize(tok) for tok in tokens]\n",
    "        tokenized_sentence.append(tokens)\n",
    "    tokenized_df.insert(1, 'tokens', tokenized_sentence)\n",
    "    tokenized_df.drop('concat_tweet',axis=1,inplace=True)\n",
    "    return tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3f1b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[regularly, rinse, nose, saline, help, prevent...</td>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[french, police, chief, kill, charliehebdo, at...</td>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[coronavirus, disease, covid, advice, public, ...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ottawa, police, confirm, multiple, suspect, s...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[primary, focus, government, isnt, alleviate, ...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  sentiment  \\\n",
       "0  [regularly, rinse, nose, saline, help, prevent...   0.173437   \n",
       "1  [french, police, chief, kill, charliehebdo, at...  -0.278125   \n",
       "2  [coronavirus, disease, covid, advice, public, ...   0.133333   \n",
       "3  [ottawa, police, confirm, multiple, suspect, s...   0.133333   \n",
       "4  [primary, focus, government, isnt, alleviate, ...   0.400000   \n",
       "\n",
       "              user  verified  likes  retweets  label  \n",
       "0        ucoptempe         0      0         0      0  \n",
       "1        Telegraph         1     43       184      1  \n",
       "2  kareem_alnakeeb         0      3         1      0  \n",
       "3              WSJ         1     23       119      0  \n",
       "4     hoss_bossman         0      6         1      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = tokenize_df(train_full_df)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91b635dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[covid, fact, hand, dryer, effective, kill, ne...</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>WeatherBug</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[expect, result, husband, pendingantibody, tes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ewart_lynne</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[covid, spread, people, catch, covid, others, ...</td>\n",
       "      <td>0.026257</td>\n",
       "      <td>Agali_GCFR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[every, news, outlet, use, headline, like, ant...</td>\n",
       "      <td>-0.056439</td>\n",
       "      <td>TuckyAalto</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[researcher, encounter, goliath, birdeater, wo...</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  sentiment         user  \\\n",
       "0  [covid, fact, hand, dryer, effective, kill, ne...   0.484091   WeatherBug   \n",
       "1  [expect, result, husband, pendingantibody, tes...   0.000000  ewart_lynne   \n",
       "2  [covid, spread, people, catch, covid, others, ...   0.026257   Agali_GCFR   \n",
       "3  [every, news, outlet, use, headline, like, ant...  -0.056439   TuckyAalto   \n",
       "4  [researcher, encounter, goliath, birdeater, wo...   0.168182      Harvard   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0         0      6         1      0  \n",
       "1         0      0         0      0  \n",
       "2         0      0         0      0  \n",
       "3         0     17         0      0  \n",
       "4         1     71       149      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_full_df = tokenize_df(dev_full_df)\n",
    "dev_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de35c2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[covid, spread, thank, wcco, station, trust, m...</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>WCCO</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hate, keep, say, capitalism, implode, without...</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>Kikasitsu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[covid, influenza, virus, different, covid, co...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>CovidIreland</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[una, de, le, coronaviruses, de, la, pgina, we...</td>\n",
       "      <td>0.068466</td>\n",
       "      <td>PerePuigUAB</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[absolutely, blame, politician, whoever, else,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>klarth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>[exmarlboro, man, die, smokingrelated, disease...</td>\n",
       "      <td>0.174937</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>[holy, shit, doritos, flavor, mountain, dew, l...</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>Boogie2988</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[banksy, account, join, cartoonist, support, c...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>ThePoke</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[member, international, heal, member, adviser,...</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>WHO</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[covid, catch, person, symptom, main, way, dis...</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  sentiment  \\\n",
       "0    [covid, spread, thank, wcco, station, trust, m...   0.183333   \n",
       "1    [hate, keep, say, capitalism, implode, without...  -0.160000   \n",
       "2    [covid, influenza, virus, different, covid, co...   0.100000   \n",
       "3    [una, de, le, coronaviruses, de, la, pgina, we...   0.068466   \n",
       "4    [absolutely, blame, politician, whoever, else,...   0.333333   \n",
       "..                                                 ...        ...   \n",
       "553  [exmarlboro, man, die, smokingrelated, disease...   0.174937   \n",
       "554  [holy, shit, doritos, flavor, mountain, dew, l...   0.043953   \n",
       "555  [banksy, account, join, cartoonist, support, c...   0.083333   \n",
       "556  [member, international, heal, member, adviser,...   0.233333   \n",
       "557  [covid, catch, person, symptom, main, way, dis...   0.241667   \n",
       "\n",
       "               user  verified  likes  retweets  \n",
       "0              WCCO         1      4         0  \n",
       "1         Kikasitsu         0      0         0  \n",
       "2      CovidIreland         0      2         0  \n",
       "3       PerePuigUAB         0      3         4  \n",
       "4            klarth         0      0         0  \n",
       "..              ...       ...    ...       ...  \n",
       "553  washingtonpost         1     26       139  \n",
       "554      Boogie2988         1    342       181  \n",
       "555         ThePoke         1    230       350  \n",
       "556             WHO         1     47        19  \n",
       "557   mugabo_robert         0      1         1  \n",
       "\n",
       "[558 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_df = tokenize_df(test_full_df)\n",
    "test_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "964e0e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 2250,\n",
       " 'coronavirus': 1899,\n",
       " 'people': 1639,\n",
       " 'new': 1558,\n",
       " 'virus': 1071,\n",
       " 'get': 865,\n",
       " 'say': 785,\n",
       " 'like': 782,\n",
       " 'dont': 645,\n",
       " 'prevent': 609,\n",
       " 'make': 588,\n",
       " 'know': 581,\n",
       " 'go': 580,\n",
       " 'kill': 577,\n",
       " 'spread': 550,\n",
       " 'one': 534,\n",
       " 'take': 533,\n",
       " 'think': 528,\n",
       " 'need': 519,\n",
       " 'see': 510,\n",
       " 'u': 495,\n",
       " 'disease': 481,\n",
       " 'would': 474,\n",
       " 'hand': 473,\n",
       " 'rt': 446,\n",
       " 'test': 442,\n",
       " 'good': 442,\n",
       " 'person': 429,\n",
       " 'symptom': 419,\n",
       " 'protect': 412,\n",
       " 'time': 406,\n",
       " 'infect': 398,\n",
       " 'use': 396,\n",
       " 'infection': 391,\n",
       " 'im': 381,\n",
       " 'help': 374,\n",
       " 'may': 371,\n",
       " 'thats': 363,\n",
       " 'day': 360,\n",
       " 'spider': 360,\n",
       " 'die': 351,\n",
       " 'effective': 348,\n",
       " 'work': 346,\n",
       " 'cough': 336,\n",
       " 'case': 336,\n",
       " 'give': 334,\n",
       " 'cause': 326,\n",
       " 'death': 317,\n",
       " 'want': 315,\n",
       " 'someone': 314,\n",
       " 'treat': 311,\n",
       " 'report': 310,\n",
       " 'mask': 306,\n",
       " 'look': 304,\n",
       " 'wear': 302,\n",
       " 'come': 302,\n",
       " 'shoot': 300,\n",
       " 'catch': 298,\n",
       " 'transmit': 295,\n",
       " 'also': 293,\n",
       " 'still': 282,\n",
       " 'nose': 280,\n",
       " 'way': 278,\n",
       " 'even': 278,\n",
       " 'thank': 274,\n",
       " 'vaccine': 268,\n",
       " 'find': 268,\n",
       " 'china': 267,\n",
       " 'right': 266,\n",
       " 'world': 265,\n",
       " 'mean': 262,\n",
       " 'health': 260,\n",
       " 'news': 260,\n",
       " 'woman': 258,\n",
       " 'well': 256,\n",
       " 'ncov': 251,\n",
       " 'hot': 248,\n",
       " 'really': 248,\n",
       " 'thing': 244,\n",
       " 'many': 244,\n",
       " 'home': 243,\n",
       " 'antibiotic': 241,\n",
       " 'stop': 238,\n",
       " 'care': 237,\n",
       " 'country': 237,\n",
       " 'much': 237,\n",
       " 'live': 235,\n",
       " 'first': 234,\n",
       " 'eat': 229,\n",
       " 'become': 229,\n",
       " 'droplet': 229,\n",
       " 'show': 227,\n",
       " 'call': 226,\n",
       " 'puppysized': 224,\n",
       " 'safe': 222,\n",
       " 'could': 221,\n",
       " 'please': 221,\n",
       " 'spray': 220,\n",
       " 'fact': 220,\n",
       " 'body': 219,\n",
       " 'respiratory': 219,\n",
       " 'scientist': 217,\n",
       " 'stay': 215,\n",
       " 'water': 215,\n",
       " 'paul': 212,\n",
       " 'lol': 211,\n",
       " 'evidence': 211,\n",
       " 'tell': 210,\n",
       " 'love': 210,\n",
       " 'follow': 207,\n",
       " 'walker': 207,\n",
       " 'police': 206,\n",
       " 'year': 206,\n",
       " 'break': 206,\n",
       " 'oh': 205,\n",
       " 'man': 205,\n",
       " 'let': 204,\n",
       " 'surprise': 201,\n",
       " 'cant': 200,\n",
       " 'put': 198,\n",
       " 'part': 198,\n",
       " 'sad': 196,\n",
       " 'rainforest': 196,\n",
       " 'specific': 195,\n",
       " 'god': 194,\n",
       " 'try': 192,\n",
       " 'risk': 192,\n",
       " 'immunity': 192,\n",
       " 'president': 191,\n",
       " 'yes': 191,\n",
       " 'around': 184,\n",
       " 'fuck': 183,\n",
       " 'feel': 182,\n",
       " 'million': 181,\n",
       " 'medical': 181,\n",
       " 'rip': 180,\n",
       " 'medicine': 180,\n",
       " 'affect': 179,\n",
       " 'sick': 179,\n",
       " 'true': 179,\n",
       " 'food': 179,\n",
       " 'white': 178,\n",
       " 'flu': 178,\n",
       " 'cannot': 177,\n",
       " 'older': 177,\n",
       " 'confirm': 176,\n",
       " 'touch': 175,\n",
       " 'happen': 174,\n",
       " 'area': 172,\n",
       " 'family': 172,\n",
       " 'fever': 172,\n",
       " 'la': 171,\n",
       " 'surface': 171,\n",
       " 'garlic': 170,\n",
       " 'everyone': 170,\n",
       " 'g': 169,\n",
       " 'big': 169,\n",
       " 'iphone': 169,\n",
       " 'sure': 168,\n",
       " 'however': 167,\n",
       " 'florida': 167,\n",
       " 'complexmag': 166,\n",
       " 'number': 165,\n",
       " 'myth': 165,\n",
       " 'doesnt': 164,\n",
       " 'long': 164,\n",
       " 'third': 164,\n",
       " 'better': 163,\n",
       " 'include': 163,\n",
       " 'wash': 163,\n",
       " 'guy': 162,\n",
       " 'mouth': 162,\n",
       " 'human': 161,\n",
       " 'great': 161,\n",
       " 'believe': 160,\n",
       " 'keep': 159,\n",
       " 'develop': 157,\n",
       " 'dead': 156,\n",
       " 'alcohol': 155,\n",
       " 'back': 155,\n",
       " 'didnt': 154,\n",
       " 'real': 153,\n",
       " 'life': 153,\n",
       " 'cold': 152,\n",
       " 'obama': 152,\n",
       " 'last': 152,\n",
       " 'contact': 149,\n",
       " 'breathe': 149,\n",
       " 'read': 147,\n",
       " 'date': 146,\n",
       " 'city': 146,\n",
       " 'hope': 145,\n",
       " 'result': 145,\n",
       " 'regularly': 143,\n",
       " 'without': 142,\n",
       " 'soldier': 142,\n",
       " 'pocket': 142,\n",
       " 'herd': 142,\n",
       " 'treatment': 141,\n",
       " 'ill': 141,\n",
       " 'team': 141,\n",
       " 'bend': 140,\n",
       " 'pneumonia': 139,\n",
       " 'add': 139,\n",
       " 'word': 138,\n",
       " 'wont': 137,\n",
       " 'yet': 137,\n",
       " 'seem': 137,\n",
       " 'question': 136,\n",
       " 'buzzfeed': 136,\n",
       " 'house': 135,\n",
       " 'public': 134,\n",
       " 'outbreak': 134,\n",
       " 'air': 134,\n",
       " 'source': 134,\n",
       " 'never': 134,\n",
       " 'others': 133,\n",
       " 'animal': 133,\n",
       " 'dew': 133,\n",
       " 'pay': 131,\n",
       " 'watch': 131,\n",
       " 'two': 130,\n",
       " 'fast': 129,\n",
       " 'receive': 129,\n",
       " 'do': 129,\n",
       " 'vega': 129,\n",
       " 'south': 128,\n",
       " 'wow': 127,\n",
       " 'state': 127,\n",
       " 'hostage': 127,\n",
       " 'mountain': 127,\n",
       " 'weather': 126,\n",
       " 'government': 126,\n",
       " 'place': 126,\n",
       " 'ask': 126,\n",
       " 'update': 125,\n",
       " 'dog': 125,\n",
       " 'expansion': 125,\n",
       " 'problem': 124,\n",
       " 'hear': 124,\n",
       " 'penis': 123,\n",
       " 'talk': 123,\n",
       " 'clean': 122,\n",
       " 'leave': 122,\n",
       " 'information': 122,\n",
       " 'buy': 122,\n",
       " 'photo': 122,\n",
       " 'shit': 121,\n",
       " 'war': 120,\n",
       " 'age': 120,\n",
       " 'something': 120,\n",
       " 'must': 118,\n",
       " 'child': 118,\n",
       " 'run': 118,\n",
       " 'nhl': 118,\n",
       " 'rinse': 117,\n",
       " 'bite': 117,\n",
       " 'wrong': 117,\n",
       " 'common': 117,\n",
       " 'isnt': 116,\n",
       " 'hell': 116,\n",
       " 'bugatti': 116,\n",
       " 'youre': 116,\n",
       " 'severe': 116,\n",
       " 'week': 116,\n",
       " 'paint': 116,\n",
       " 'issue': 116,\n",
       " 'daughter': 116,\n",
       " 'maybe': 115,\n",
       " 'eye': 115,\n",
       " 'obamas': 115,\n",
       " 'doritosflavored': 115,\n",
       " 'best': 114,\n",
       " 'another': 113,\n",
       " 'bad': 113,\n",
       " 'answer': 113,\n",
       " 'system': 112,\n",
       " 'isi': 111,\n",
       " 'ban': 111,\n",
       " 'close': 111,\n",
       " 'surgery': 111,\n",
       " 'eonline': 111,\n",
       " 'susceptible': 110,\n",
       " 'fake': 110,\n",
       " 'kid': 110,\n",
       " 'package': 110,\n",
       " 'check': 109,\n",
       " 'since': 109,\n",
       " 'he': 109,\n",
       " 'detect': 108,\n",
       " 'heart': 108,\n",
       " 'point': 108,\n",
       " 'anything': 107,\n",
       " 'video': 107,\n",
       " 'black': 107,\n",
       " 'enough': 107,\n",
       " 'ever': 107,\n",
       " 'illness': 107,\n",
       " 'today': 107,\n",
       " 'job': 106,\n",
       " 'name': 105,\n",
       " 'patient': 105,\n",
       " 'share': 105,\n",
       " 'deal': 105,\n",
       " 'nope': 105,\n",
       " 'meet': 104,\n",
       " 'data': 104,\n",
       " 'saline': 103,\n",
       " 'veyron': 103,\n",
       " 'travel': 103,\n",
       " 'coronaviruses': 103,\n",
       " 'start': 102,\n",
       " 'younger': 102,\n",
       " 'measure': 102,\n",
       " 'trump': 102,\n",
       " 'tweet': 102,\n",
       " 'reportedly': 102,\n",
       " 'manager': 102,\n",
       " 'ok': 101,\n",
       " 'every': 101,\n",
       " 'suggest': 101,\n",
       " 'expect': 101,\n",
       " 'letter': 101,\n",
       " 'already': 100,\n",
       " 'possible': 100,\n",
       " 'sneeze': 100,\n",
       " 'avoid': 100,\n",
       " 'wtf': 99,\n",
       " 'might': 99,\n",
       " 'chickfila': 99,\n",
       " 'dryer': 98,\n",
       " 'le': 98,\n",
       " 'important': 98,\n",
       " 'lie': 98,\n",
       " 'bank': 98,\n",
       " 'boob': 97,\n",
       " 'yeah': 96,\n",
       " 'change': 96,\n",
       " 'hoax': 96,\n",
       " 'era': 96,\n",
       " 'pro': 96,\n",
       " 'scanner': 95,\n",
       " 'recover': 95,\n",
       " 'c': 95,\n",
       " 'ottawa': 95,\n",
       " 'healthy': 95,\n",
       " 'likely': 95,\n",
       " 'study': 95,\n",
       " 'whats': 95,\n",
       " 'allow': 95,\n",
       " 'story': 95,\n",
       " 'chlorine': 94,\n",
       " 'thermal': 94,\n",
       " 'mh': 94,\n",
       " 'understand': 94,\n",
       " 'soap': 94,\n",
       " 'claim': 94,\n",
       " 'cnn': 94,\n",
       " 'star': 94,\n",
       " 'drink': 93,\n",
       " 'face': 93,\n",
       " 'money': 93,\n",
       " 'temperature': 92,\n",
       " 'guess': 92,\n",
       " 'soon': 92,\n",
       " 'high': 92,\n",
       " 'old': 92,\n",
       " 'pet': 92,\n",
       " 'tshirt': 92,\n",
       " 'b': 91,\n",
       " 'actually': 91,\n",
       " 'furious': 91,\n",
       " 'send': 90,\n",
       " 'far': 90,\n",
       " 'free': 90,\n",
       " 'away': 90,\n",
       " 'arrest': 90,\n",
       " 'gun': 90,\n",
       " 'wonder': 89,\n",
       " 'buster': 89,\n",
       " 'nothing': 88,\n",
       " 'medium': 88,\n",
       " 'national': 88,\n",
       " 'tv': 88,\n",
       " 'jail': 88,\n",
       " 'corona': 87,\n",
       " 'lot': 87,\n",
       " 'reason': 87,\n",
       " 'network': 86,\n",
       " 'suspect': 86,\n",
       " 'memorial': 86,\n",
       " 'least': 86,\n",
       " 'via': 86,\n",
       " 'rest': 86,\n",
       " 'mosquito': 85,\n",
       " 'higher': 85,\n",
       " 'there': 85,\n",
       " 'social': 85,\n",
       " 'mild': 85,\n",
       " 'anyone': 84,\n",
       " 'miss': 84,\n",
       " 'cover': 84,\n",
       " 'puppy': 84,\n",
       " 'humid': 83,\n",
       " 'difficulty': 83,\n",
       " 'situation': 83,\n",
       " 'different': 83,\n",
       " 'th': 83,\n",
       " 'light': 83,\n",
       " 'hour': 83,\n",
       " 'climate': 82,\n",
       " 'release': 82,\n",
       " 'play': 82,\n",
       " 'bring': 82,\n",
       " 'deer': 82,\n",
       " 'hank': 82,\n",
       " 'xxl': 82,\n",
       " 'bath': 81,\n",
       " 'hold': 81,\n",
       " 'control': 81,\n",
       " 'end': 81,\n",
       " 'size': 81,\n",
       " 'exactly': 81,\n",
       " 'goliath': 81,\n",
       " 'condition': 80,\n",
       " 'idea': 80,\n",
       " 'friend': 80,\n",
       " 'rate': 80,\n",
       " 'plus': 79,\n",
       " 'support': 79,\n",
       " 'fall': 79,\n",
       " 'pandemic': 79,\n",
       " 'canadian': 78,\n",
       " 'plan': 78,\n",
       " 'low': 78,\n",
       " 'distance': 78,\n",
       " 'open': 78,\n",
       " 'official': 78,\n",
       " 'banksy': 78,\n",
       " 'frediboat': 78,\n",
       " 'probably': 77,\n",
       " 'save': 77,\n",
       " 'school': 77,\n",
       " 'positive': 77,\n",
       " 'ive': 77,\n",
       " 'taste': 77,\n",
       " 'lose': 76,\n",
       " 'gang': 76,\n",
       " 'though': 76,\n",
       " 'sars': 76,\n",
       " 'phone': 76,\n",
       " 'wait': 76,\n",
       " 'recommend': 76,\n",
       " 'stupid': 76,\n",
       " 'usa': 75,\n",
       " 'next': 75,\n",
       " 'r': 75,\n",
       " 'wasnt': 75,\n",
       " 'lego': 75,\n",
       " 'lamp': 74,\n",
       " 'everything': 74,\n",
       " 'link': 74,\n",
       " 'gay': 74,\n",
       " 'louisiana': 74,\n",
       " 'survive': 73,\n",
       " 'sweet': 73,\n",
       " 'starbucks': 73,\n",
       " 'move': 72,\n",
       " 'damn': 72,\n",
       " 'canada': 72,\n",
       " 'little': 72,\n",
       " 'twerking': 72,\n",
       " 'website': 71,\n",
       " 'pope': 71,\n",
       " 'serious': 70,\n",
       " 'factcheck': 70,\n",
       " 'birdeater': 70,\n",
       " 'mobile': 69,\n",
       " 'build': 69,\n",
       " 'sound': 69,\n",
       " 'month': 69,\n",
       " 'fight': 69,\n",
       " 'learn': 69,\n",
       " 'fire': 69,\n",
       " 'yall': 69,\n",
       " 'slang': 69,\n",
       " 'discover': 68,\n",
       " 'ferguson': 68,\n",
       " 'small': 68,\n",
       " 'novel': 68,\n",
       " 'employee': 68,\n",
       " 'reality': 68,\n",
       " 'lord': 68,\n",
       " 'attack': 67,\n",
       " 'muslim': 67,\n",
       " 'law': 67,\n",
       " 'x': 67,\n",
       " 'order': 67,\n",
       " 'continue': 67,\n",
       " 'post': 67,\n",
       " 'id': 67,\n",
       " 'sugarhill': 67,\n",
       " 'able': 66,\n",
       " 'girl': 66,\n",
       " 'hospital': 66,\n",
       " 'peace': 66,\n",
       " 'parent': 66,\n",
       " 'mt': 66,\n",
       " 'de': 66,\n",
       " 'dangerous': 65,\n",
       " 'n': 65,\n",
       " 'begin': 65,\n",
       " 'several': 65,\n",
       " 'rather': 65,\n",
       " 'always': 65,\n",
       " 'large': 65,\n",
       " 'current': 65,\n",
       " 'provide': 65,\n",
       " 'pepsi': 65,\n",
       " 'whole': 64,\n",
       " 'car': 64,\n",
       " 'base': 64,\n",
       " 'remember': 64,\n",
       " 'alive': 64,\n",
       " 'breast': 64,\n",
       " 'guinness': 64,\n",
       " 'mashable': 63,\n",
       " 'experience': 63,\n",
       " 'early': 63,\n",
       " 'simple': 63,\n",
       " 'owner': 63,\n",
       " 'population': 63,\n",
       " 'kind': 63,\n",
       " 'hello': 63,\n",
       " 'hard': 63,\n",
       " 'movie': 63,\n",
       " 'antibody': 63,\n",
       " 'crazy': 62,\n",
       " 'blood': 62,\n",
       " 'research': 62,\n",
       " 'uk': 62,\n",
       " 'surgically': 62,\n",
       " 'latte': 62,\n",
       " 'expose': 61,\n",
       " 'w': 61,\n",
       " 'wuhan': 61,\n",
       " 'frequently': 61,\n",
       " 'member': 61,\n",
       " 'rainbow': 61,\n",
       " 'fakenews': 61,\n",
       " 'interest': 60,\n",
       " 'appear': 60,\n",
       " 'worry': 60,\n",
       " 'foxnews': 60,\n",
       " 'e': 60,\n",
       " 'speak': 60,\n",
       " 'transmission': 60,\n",
       " 'omg': 60,\n",
       " 'night': 60,\n",
       " 'example': 59,\n",
       " 'diabetes': 59,\n",
       " 'seriously': 59,\n",
       " 'vote': 59,\n",
       " 'lockdown': 59,\n",
       " 'list': 59,\n",
       " 'step': 59,\n",
       " 'book': 59,\n",
       " 'paris': 59,\n",
       " 'k': 59,\n",
       " 'bid': 59,\n",
       " 'second': 58,\n",
       " 'advice': 58,\n",
       " 'funny': 58,\n",
       " 'hey': 58,\n",
       " 'hi': 58,\n",
       " 'turn': 58,\n",
       " 'seek': 58,\n",
       " 'individual': 58,\n",
       " 'terrorist': 57,\n",
       " 'act': 57,\n",
       " 'reduce': 57,\n",
       " 'theyre': 57,\n",
       " 'especially': 57,\n",
       " 'article': 57,\n",
       " 'saw': 57,\n",
       " 'info': 57,\n",
       " 'poor': 56,\n",
       " 'object': 56,\n",
       " 'protection': 56,\n",
       " 'parliament': 56,\n",
       " 'happy': 56,\n",
       " 'ppl': 56,\n",
       " 'worker': 56,\n",
       " 'fanged': 56,\n",
       " 'toronto': 56,\n",
       " 'fxnscitech': 56,\n",
       " 'snow': 55,\n",
       " 'shooter': 55,\n",
       " 'sense': 55,\n",
       " 'mass': 55,\n",
       " 'authority': 55,\n",
       " 'head': 55,\n",
       " 'etc': 55,\n",
       " 'period': 55,\n",
       " 'gunman': 55,\n",
       " 'sorry': 54,\n",
       " 'type': 54,\n",
       " 'alcoholbased': 54,\n",
       " 'sit': 54,\n",
       " 'agree': 54,\n",
       " 'full': 54,\n",
       " 'hate': 54,\n",
       " 'enter': 54,\n",
       " 'fear': 54,\n",
       " 'ago': 54,\n",
       " 'doctor': 53,\n",
       " 'drug': 53,\n",
       " 'course': 53,\n",
       " 'available': 53,\n",
       " 'increase': 53,\n",
       " 'gonna': 53,\n",
       " 'total': 53,\n",
       " 'recall': 53,\n",
       " 'joke': 53,\n",
       " 'matter': 53,\n",
       " 'influenza': 53,\n",
       " 'seattle': 53,\n",
       " 'charlie': 52,\n",
       " 'victim': 52,\n",
       " 'action': 52,\n",
       " 'instead': 52,\n",
       " 'cop': 52,\n",
       " 'color': 52,\n",
       " 'therefore': 52,\n",
       " 'shut': 52,\n",
       " 'cure': 52,\n",
       " 'remain': 52,\n",
       " 'prayer': 52,\n",
       " 'delay': 52,\n",
       " 'sydney': 52,\n",
       " 'passenger': 52,\n",
       " 'abandon': 52,\n",
       " 'behead': 51,\n",
       " 'record': 51,\n",
       " 'foot': 51,\n",
       " 'independent': 51,\n",
       " 'local': 51,\n",
       " 'rule': 51,\n",
       " 'young': 51,\n",
       " 'expert': 51,\n",
       " 'highly': 51,\n",
       " 'airborne': 51,\n",
       " 'pop': 51,\n",
       " 'disinfection': 50,\n",
       " 'plane': 50,\n",
       " 'listen': 50,\n",
       " 'range': 50,\n",
       " 'rub': 50,\n",
       " 'evil': 50,\n",
       " 'present': 50,\n",
       " 'group': 50,\n",
       " 'belong': 50,\n",
       " 'burgerking': 50,\n",
       " 'hebdo': 49,\n",
       " 'nice': 49,\n",
       " 'pregnant': 49,\n",
       " 'mind': 49,\n",
       " 'party': 49,\n",
       " 'visit': 49,\n",
       " 'disgust': 49,\n",
       " 'immune': 49,\n",
       " 'hit': 49,\n",
       " 'punishment': 49,\n",
       " 'set': 49,\n",
       " 'adopt': 49,\n",
       " 'scrap': 49,\n",
       " 'nurse': 49,\n",
       " 'dailymail': 49,\n",
       " 'ultraviolet': 48,\n",
       " 'p': 48,\n",
       " 'arent': 48,\n",
       " 'dry': 48,\n",
       " 'rat': 48,\n",
       " 'advise': 48,\n",
       " 'que': 48,\n",
       " 'else': 48,\n",
       " 'truth': 48,\n",
       " 'contaminate': 48,\n",
       " 'fee': 48,\n",
       " 'walk': 48,\n",
       " 'sign': 48,\n",
       " 'v': 47,\n",
       " 'latest': 47,\n",
       " 'pretty': 47,\n",
       " 'prevention': 47,\n",
       " 'community': 47,\n",
       " 'wouldnt': 47,\n",
       " 'per': 47,\n",
       " 'idiot': 47,\n",
       " 'poll': 47,\n",
       " 'govt': 47,\n",
       " 'illegal': 47,\n",
       " 'false': 46,\n",
       " 'tragic': 46,\n",
       " 'contract': 46,\n",
       " 'david': 46,\n",
       " 'science': 46,\n",
       " 'due': 46,\n",
       " 'powerful': 46,\n",
       " 'pourmecoffee': 46,\n",
       " 'ya': 45,\n",
       " 'concern': 45,\n",
       " 'paper': 45,\n",
       " 'consider': 45,\n",
       " 'tissue': 45,\n",
       " 'boy': 45,\n",
       " 'normal': 45,\n",
       " 'bacteria': 45,\n",
       " 'regardless': 45,\n",
       " 'near': 44,\n",
       " 'explain': 44,\n",
       " 'italy': 44,\n",
       " 'organization': 44,\n",
       " 'worst': 44,\n",
       " 'exist': 44,\n",
       " 'force': 44,\n",
       " 'choose': 44,\n",
       " 'twitter': 44,\n",
       " 'create': 44,\n",
       " 'wish': 44,\n",
       " 'station': 44,\n",
       " 'crash': 44,\n",
       " 'chocolate': 44,\n",
       " 'picture': 44,\n",
       " 'kkk': 44,\n",
       " 'radioactive': 44,\n",
       " 'impose': 44,\n",
       " 'ha': 43,\n",
       " 'sun': 43,\n",
       " 'charliehebdo': 43,\n",
       " 'shouldnt': 43,\n",
       " 'mainly': 43,\n",
       " 'leader': 43,\n",
       " 'trust': 43,\n",
       " 'havent': 43,\n",
       " 'fukushima': 43,\n",
       " 'huffingtonpost': 43,\n",
       " 'three': 42,\n",
       " 'putin': 42,\n",
       " 'offer': 42,\n",
       " 'previous': 42,\n",
       " 'immediately': 42,\n",
       " 'chance': 42,\n",
       " 'company': 42,\n",
       " 'stand': 42,\n",
       " 'cut': 42,\n",
       " 'shame': 42,\n",
       " 'beautiful': 42,\n",
       " 'decision': 42,\n",
       " 'draw': 42,\n",
       " 'train': 42,\n",
       " 'pumpkin': 42,\n",
       " 'ibuprofen': 42,\n",
       " 'breath': 41,\n",
       " 'behind': 41,\n",
       " 'outside': 41,\n",
       " 'lead': 41,\n",
       " 'exhale': 41,\n",
       " 'usually': 41,\n",
       " 'business': 41,\n",
       " 'mention': 41,\n",
       " 'limit': 41,\n",
       " 'interview': 41,\n",
       " 'prove': 41,\n",
       " 'meat': 41,\n",
       " 'estimate': 41,\n",
       " 'top': 41,\n",
       " 'attention': 41,\n",
       " 'shes': 41,\n",
       " 'mom': 41,\n",
       " 'foxphilly': 41,\n",
       " 'offense': 41,\n",
       " 'driver': 40,\n",
       " 'smh': 40,\n",
       " 'lmao': 40,\n",
       " 'di': 40,\n",
       " 'pick': 40,\n",
       " 'main': 40,\n",
       " 'site': 40,\n",
       " 'lung': 40,\n",
       " 'pm': 40,\n",
       " 'declare': 40,\n",
       " 'tax': 40,\n",
       " 'physical': 40,\n",
       " 'el': 40,\n",
       " 'sell': 40,\n",
       " 'finally': 40,\n",
       " 'hill': 40,\n",
       " 'thread': 40,\n",
       " 'response': 40,\n",
       " 'clear': 40,\n",
       " 'yr': 40,\n",
       " 'condom': 40,\n",
       " 'leak': 40,\n",
       " 'fakebuster': 40,\n",
       " 'katrinalome': 40,\n",
       " 'infectious': 39,\n",
       " 'quickly': 39,\n",
       " 'murder': 39,\n",
       " 'worse': 39,\n",
       " 'either': 39,\n",
       " 'together': 39,\n",
       " 'cat': 39,\n",
       " 'aint': 39,\n",
       " 'message': 39,\n",
       " 'skin': 39,\n",
       " 'harry': 39,\n",
       " 'level': 38,\n",
       " 'accord': 38,\n",
       " 'daily': 38,\n",
       " 'syndrome': 38,\n",
       " 'contain': 38,\n",
       " 'game': 38,\n",
       " 'throw': 38,\n",
       " 'speed': 38,\n",
       " 'dear': 38,\n",
       " 'destroy': 38,\n",
       " 'sir': 38,\n",
       " 'currently': 38,\n",
       " 'late': 38,\n",
       " 'grow': 38,\n",
       " 'burn': 38,\n",
       " 'bet': 37,\n",
       " 'rid': 37,\n",
       " 'preexist': 37,\n",
       " 'knowthefacts': 37,\n",
       " 'practice': 37,\n",
       " 'alone': 37,\n",
       " 'variety': 37,\n",
       " 'cancer': 37,\n",
       " 'spice': 37,\n",
       " 'stephen': 37,\n",
       " 'chinese': 36,\n",
       " 'breakfast': 36,\n",
       " 'inside': 36,\n",
       " 'ur': 36,\n",
       " 'forget': 36,\n",
       " 'throat': 36,\n",
       " 'da': 36,\n",
       " 'slow': 36,\n",
       " 'oil': 36,\n",
       " 'dude': 36,\n",
       " 'st': 36,\n",
       " 'harmful': 36,\n",
       " 'whether': 36,\n",
       " 'amaze': 36,\n",
       " 'scar': 36,\n",
       " 'negative': 36,\n",
       " 'hop': 36,\n",
       " 'glove': 36,\n",
       " 'men': 36,\n",
       " 'red': 36,\n",
       " 'tmz': 36,\n",
       " 'wake': 36,\n",
       " 'mandatory': 36,\n",
       " 'nigeria': 36,\n",
       " 'bestpronews': 36,\n",
       " 'minister': 35,\n",
       " 'comment': 35,\n",
       " 'charge': 35,\n",
       " 'choice': 35,\n",
       " 'land': 35,\n",
       " 'history': 35,\n",
       " 'recently': 35,\n",
       " 'ongoing': 35,\n",
       " 'uv': 35,\n",
       " 'ie': 35,\n",
       " 'stuff': 35,\n",
       " 'king': 35,\n",
       " 'effect': 35,\n",
       " 'require': 35,\n",
       " 'win': 35,\n",
       " 'asymptomatic': 35,\n",
       " 'racist': 35,\n",
       " 'shot': 35,\n",
       " 'gt': 35,\n",
       " 'fail': 35,\n",
       " 'refugee': 35,\n",
       " 'marlboro': 35,\n",
       " 'ocean': 35,\n",
       " 'suitcase': 35,\n",
       " 'flag': 34,\n",
       " 'cdc': 34,\n",
       " 'trial': 34,\n",
       " 'bless': 34,\n",
       " 'baby': 34,\n",
       " 'meter': 34,\n",
       " 'bear': 34,\n",
       " 'mers': 34,\n",
       " 'aware': 34,\n",
       " 'thought': 34,\n",
       " 'military': 34,\n",
       " 'warn': 34,\n",
       " 'later': 34,\n",
       " 'return': 34,\n",
       " 'weve': 34,\n",
       " 'store': 34,\n",
       " 'grocery': 34,\n",
       " 'market': 34,\n",
       " 'dr': 34,\n",
       " 'proof': 34,\n",
       " 'healthcare': 34,\n",
       " 'nestl': 34,\n",
       " 'burger': 34,\n",
       " 'dewitos': 34,\n",
       " 'facility': 34,\n",
       " 'durex': 34,\n",
       " 'boko': 34,\n",
       " 'sleep': 33,\n",
       " 'race': 33,\n",
       " 'global': 33,\n",
       " 'runny': 33,\n",
       " 'pressure': 33,\n",
       " 'identify': 33,\n",
       " 'unwell': 33,\n",
       " 'special': 33,\n",
       " 'thoroughly': 33,\n",
       " 'bacterial': 33,\n",
       " 'feature': 33,\n",
       " 'sarscov': 33,\n",
       " 'direct': 33,\n",
       " 'absolutely': 33,\n",
       " 'ebola': 33,\n",
       " 'newcrownvirus': 33,\n",
       " 'monday': 33,\n",
       " 'cafe': 33,\n",
       " 'january': 33,\n",
       " 'uberfacts': 33,\n",
       " 'jamie': 33,\n",
       " 'experiment': 33,\n",
       " 'haram': 33,\n",
       " 'sydneysiege': 32,\n",
       " 'middle': 32,\n",
       " 'dumb': 32,\n",
       " 'prepare': 32,\n",
       " 'haines': 32,\n",
       " 'cool': 32,\n",
       " 'en': 32,\n",
       " 'correct': 32,\n",
       " 'holy': 32,\n",
       " 'fill': 32,\n",
       " 'detail': 32,\n",
       " 'inform': 32,\n",
       " 'vulnerable': 32,\n",
       " 'view': 32,\n",
       " 'symptomatic': 32,\n",
       " 'ukraine': 32,\n",
       " 'internet': 32,\n",
       " 'four': 32,\n",
       " 'plant': 32,\n",
       " 'grey': 32,\n",
       " 'hip': 32,\n",
       " 'nd': 31,\n",
       " 'terrible': 31,\n",
       " 'non': 31,\n",
       " 'citizen': 31,\n",
       " 'side': 31,\n",
       " 'officer': 31,\n",
       " 'sore': 31,\n",
       " 'service': 31,\n",
       " 'smoke': 31,\n",
       " 'pas': 31,\n",
       " 'power': 31,\n",
       " 'heaven': 31,\n",
       " 'property': 31,\n",
       " 'marriage': 31,\n",
       " 'couldnt': 31,\n",
       " 'bruh': 31,\n",
       " 'similar': 31,\n",
       " 'block': 31,\n",
       " 'billion': 31,\n",
       " 'emergency': 31,\n",
       " 'malaysia': 31,\n",
       " 'event': 31,\n",
       " 'value': 31,\n",
       " 'compare': 31,\n",
       " 'appearance': 31,\n",
       " 'beer': 31,\n",
       " 'international': 31,\n",
       " 'potter': 31,\n",
       " 'shade': 31,\n",
       " 'reaitupac': 31,\n",
       " 'dispose': 30,\n",
       " 'statement': 30,\n",
       " 'missile': 30,\n",
       " 'difference': 30,\n",
       " 'completely': 30,\n",
       " 'shutdown': 30,\n",
       " 'suppose': 30,\n",
       " 'economy': 30,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tokens(df):\n",
    "    token_counts = {}\n",
    "    for token_list in list(df['tokens']):\n",
    "        for token in token_list:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "    return {k: v for k, v in sorted(token_counts.items(), key=lambda item: item[1],reverse=True)}\n",
    "            \n",
    "unigram_counts = count_tokens(train_full_df)\n",
    "unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc90e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = {}\n",
    "repeat_users = []\n",
    "\n",
    "for user in train_full_df['user']:\n",
    "    if user == 'mashable':\n",
    "        if 'u_mashable' in user_counts:\n",
    "            user_counts['u_mashable'] +=1\n",
    "        else:\n",
    "            user_counts['u_mashable'] = 1\n",
    "    elif user in user_counts:\n",
    "        user_counts[user] +=1\n",
    "    else:\n",
    "        user_counts[user] = 1\n",
    "        \n",
    "for k, v in user_counts.items():\n",
    "    if v > 1:\n",
    "        repeat_users.append(k)\n",
    "        \n",
    "repeat_users\n",
    "\n",
    "def top_users(df, repeat_users):\n",
    "    df_new = df\n",
    "    df_new = df_new.reindex(columns = list(df_new.columns) + repeat_users, fill_value = 0)\n",
    "    for i, row in df_new.iterrows():\n",
    "        if row['user'] == 'mashable':\n",
    "            df_new.at[i, 'u_mashable'] = 1\n",
    "        elif row['user'] in repeat_users:\n",
    "            df_new.at[i, row['user']] = 1\n",
    "    df_new.drop(['user'],axis=1,inplace=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb20072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>...</th>\n",
       "      <th>employee</th>\n",
       "      <th>reality</th>\n",
       "      <th>lord</th>\n",
       "      <th>attack</th>\n",
       "      <th>muslim</th>\n",
       "      <th>law</th>\n",
       "      <th>x</th>\n",
       "      <th>order</th>\n",
       "      <th>continue</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.040770</td>\n",
       "      <td>sattykrosse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>-0.191270</td>\n",
       "      <td>Bipartisanism</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.031427</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>-0.057692</td>\n",
       "      <td>NBCNews</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>-0.005323</td>\n",
       "      <td>rosierawle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment             user  verified  likes  retweets  covid  \\\n",
       "0      0.173437        ucoptempe         0      0         0      1   \n",
       "1     -0.278125        Telegraph         1     43       184      0   \n",
       "2      0.133333  kareem_alnakeeb         0      3         1      1   \n",
       "3      0.133333              WSJ         1     23       119      0   \n",
       "4      0.400000     hoss_bossman         0      6         1      0   \n",
       "...         ...              ...       ...    ...       ...    ...   \n",
       "1559   0.040770      sattykrosse         0      0         0      1   \n",
       "1560  -0.191270    Bipartisanism         1     56        76      0   \n",
       "1561   0.031427              ABC         1    148       108      0   \n",
       "1562  -0.057692          NBCNews         1     63       176      0   \n",
       "1563  -0.005323       rosierawle         0      0         0      0   \n",
       "\n",
       "      coronavirus  people  new  virus  ...  employee  reality  lord  attack  \\\n",
       "0               1       1    1      1  ...         0        0     0       0   \n",
       "1               0       0    0      0  ...         0        0     0       1   \n",
       "2               1       0    0      0  ...         0        0     0       0   \n",
       "3               0       1    0      0  ...         0        0     0       1   \n",
       "4               0       0    0      0  ...         0        0     0       0   \n",
       "...           ...     ...  ...    ...  ...       ...      ...   ...     ...   \n",
       "1559            1       1    1      1  ...         0        0     0       0   \n",
       "1560            0       0    0      0  ...         0        0     0       0   \n",
       "1561            0       0    1      0  ...         0        0     0       0   \n",
       "1562            0       0    0      0  ...         0        0     0       0   \n",
       "1563            0       0    1      0  ...         0        0     0       0   \n",
       "\n",
       "      muslim  law  x  order  continue  post  \n",
       "0          0    0  0      0         0     0  \n",
       "1          0    0  0      0         0     0  \n",
       "2          0    0  0      0         0     0  \n",
       "3          0    0  0      0         0     0  \n",
       "4          0    0  0      0         0     0  \n",
       "...      ...  ... ..    ...       ...   ...  \n",
       "1559       0    0  0      0         0     0  \n",
       "1560       0    0  0      0         0     0  \n",
       "1561       0    1  0      0         0     0  \n",
       "1562       0    0  0      0         0     0  \n",
       "1563       0    0  0      0         0     0  \n",
       "\n",
       "[1552 rows x 505 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_n(df, n):\n",
    "    return list(df.columns)+list(unigram_counts.keys())[0:n]\n",
    "\n",
    "def df_top_tokens(df, cols):\n",
    "    df_new = df\n",
    "    df_new = df_new.reindex(columns=cols, fill_value=0)\n",
    "    for i, row in df_new.iterrows():\n",
    "        for token in row['tokens']:\n",
    "            if token in list(df_new.columns):\n",
    "                df_new.at[i, token] = 1\n",
    "    df_new.drop(['tokens'],axis=1,inplace=True)\n",
    "    return df_new\n",
    "\n",
    "y_train = train_full_df['label']\n",
    "y_dev = dev_full_df['label']\n",
    "\n",
    "train_full_df.drop('label',axis=1,inplace=True)\n",
    "dev_full_df.drop('label',axis=1,inplace=True)\n",
    "\n",
    "cols_500 = top_n(train_full_df, 500)\n",
    "cols_1000 = top_n(train_full_df, 1000)\n",
    "\n",
    "train_df_500 = df_top_tokens(train_full_df, cols_500)\n",
    "dev_df_500 = df_top_tokens(dev_full_df, cols_500)\n",
    "test_df_500 = df_top_tokens(test_full_df, cols_500)\n",
    "\n",
    "train_df_1000 = df_top_tokens(train_full_df, cols_1000)\n",
    "dev_df_1000 = df_top_tokens(dev_full_df, cols_1000)\n",
    "test_df_1000 = df_top_tokens(test_full_df, cols_1000)\n",
    "\n",
    "train_df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07e7f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278125</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.040770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>-0.191270</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.031427</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>-0.057692</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>-0.005323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 1162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  verified  likes  retweets  covid  coronavirus  people  new  \\\n",
       "0      0.173437         0      0         0      1            1       1    1   \n",
       "1     -0.278125         1     43       184      0            0       0    0   \n",
       "2      0.133333         0      3         1      1            1       0    0   \n",
       "3      0.133333         1     23       119      0            0       1    0   \n",
       "4      0.400000         0      6         1      0            0       0    0   \n",
       "...         ...       ...    ...       ...    ...          ...     ...  ...   \n",
       "1559   0.040770         0      0         0      1            1       1    1   \n",
       "1560  -0.191270         1     56        76      0            0       0    0   \n",
       "1561   0.031427         1    148       108      0            0       0    1   \n",
       "1562  -0.057692         1     63       176      0            0       0    0   \n",
       "1563  -0.005323         0      0         0      0            0       0    1   \n",
       "\n",
       "      virus  get  ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  \\\n",
       "0         1    0  ...              0            0            0   \n",
       "1         0    1  ...              0            0            0   \n",
       "2         0    0  ...              0            0            0   \n",
       "3         0    0  ...              0            0            0   \n",
       "4         0    0  ...              0            0            0   \n",
       "...     ...  ...  ...            ...          ...          ...   \n",
       "1559      1    0  ...              0            0            0   \n",
       "1560      0    1  ...              0            0            0   \n",
       "1561      0    1  ...              0            0            0   \n",
       "1562      0    0  ...              0            0            0   \n",
       "1563      0    0  ...              0            0            0   \n",
       "\n",
       "      washingtonpost  SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  \\\n",
       "0                  0              0                0          0   \n",
       "1                  0              0                0          0   \n",
       "2                  0              0                0          0   \n",
       "3                  0              0                0          0   \n",
       "4                  0              0                0          0   \n",
       "...              ...            ...              ...        ...   \n",
       "1559               0              0                0          0   \n",
       "1560               0              0                0          0   \n",
       "1561               0              0                0          0   \n",
       "1562               0              0                0          0   \n",
       "1563               0              0                0          0   \n",
       "\n",
       "      MANASA96592377  cahwerneck  COVIDNewsByMIB  \n",
       "0                  0           0               0  \n",
       "1                  0           0               0  \n",
       "2                  0           0               0  \n",
       "3                  0           0               0  \n",
       "4                  0           0               0  \n",
       "...              ...         ...             ...  \n",
       "1559               0           0               0  \n",
       "1560               0           0               0  \n",
       "1561               0           0               0  \n",
       "1562               0           0               0  \n",
       "1563               0           0               0  \n",
       "\n",
       "[1552 rows x 1162 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_1000_users = top_users(train_df_1000, repeat_users)\n",
    "dev_df_1000_users = top_users(dev_df_1000, repeat_users)\n",
    "test_df_1000_users = top_users(test_df_1000, repeat_users)\n",
    "\n",
    "train_df_1000_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4835ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018718</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 1162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  verified     likes  retweets  covid  coronavirus  people  \\\n",
       "0      0.586719         0  0.000000  0.000000      1            1       1   \n",
       "1      0.360938         1  0.005438  0.026096      0            0       0   \n",
       "2      0.566667         0  0.000379  0.000142      1            1       0   \n",
       "3      0.566667         1  0.002909  0.016877      0            0       1   \n",
       "4      0.700000         0  0.000759  0.000142      0            0       0   \n",
       "...         ...       ...       ...       ...    ...          ...     ...   \n",
       "1559   0.520385         0  0.000000  0.000000      1            1       1   \n",
       "1560   0.404365         1  0.007082  0.010779      0            0       0   \n",
       "1561   0.515714         1  0.018718  0.015317      0            0       0   \n",
       "1562   0.471154         1  0.007968  0.024961      0            0       0   \n",
       "1563   0.497339         0  0.000000  0.000000      0            0       0   \n",
       "\n",
       "      new  virus  get  ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  \\\n",
       "0       1      1    0  ...              0            0            0   \n",
       "1       0      0    1  ...              0            0            0   \n",
       "2       0      0    0  ...              0            0            0   \n",
       "3       0      0    0  ...              0            0            0   \n",
       "4       0      0    0  ...              0            0            0   \n",
       "...   ...    ...  ...  ...            ...          ...          ...   \n",
       "1559    1      1    0  ...              0            0            0   \n",
       "1560    0      0    1  ...              0            0            0   \n",
       "1561    1      0    1  ...              0            0            0   \n",
       "1562    0      0    0  ...              0            0            0   \n",
       "1563    1      0    0  ...              0            0            0   \n",
       "\n",
       "      washingtonpost  SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  \\\n",
       "0                  0              0                0          0   \n",
       "1                  0              0                0          0   \n",
       "2                  0              0                0          0   \n",
       "3                  0              0                0          0   \n",
       "4                  0              0                0          0   \n",
       "...              ...            ...              ...        ...   \n",
       "1559               0              0                0          0   \n",
       "1560               0              0                0          0   \n",
       "1561               0              0                0          0   \n",
       "1562               0              0                0          0   \n",
       "1563               0              0                0          0   \n",
       "\n",
       "      MANASA96592377  cahwerneck  COVIDNewsByMIB  \n",
       "0                  0           0               0  \n",
       "1                  0           0               0  \n",
       "2                  0           0               0  \n",
       "3                  0           0               0  \n",
       "4                  0           0               0  \n",
       "...              ...         ...             ...  \n",
       "1559               0           0               0  \n",
       "1560               0           0               0  \n",
       "1561               0           0               0  \n",
       "1562               0           0               0  \n",
       "1563               0           0               0  \n",
       "\n",
       "[1552 rows x 1162 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale_df(train, dev, test):\n",
    "    train_scaled = train\n",
    "    dev_scaled = dev\n",
    "    test_scaled = test\n",
    "    for col in ['sentiment','retweets','likes']:\n",
    "        if col in list(train_scaled.columns):\n",
    "            sc = MinMaxScaler().fit(train_scaled[col].values.reshape(-1,1))\n",
    "            train_scaled[col] = sc.transform(train_scaled[col].values.reshape(-1,1))\n",
    "            dev_scaled[col] = sc.transform(dev_scaled[col].values.reshape(-1,1))\n",
    "            test_scaled[col] = sc.transform(test_scaled[col].values.reshape(-1,1))\n",
    "    return train_scaled, dev_scaled, test_scaled\n",
    "\n",
    "train_df_scaled, dev_df_scaled, test_df_scaled = scale_df(train_df_1000_users, dev_df_1000_users, test_df_1000_users)\n",
    "\n",
    "train_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "991b5e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>say</th>\n",
       "      <th>like</th>\n",
       "      <th>dont</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 1159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  covid  coronavirus  people  new  virus  get  say  like  dont  \\\n",
       "0      0.586719      1            1       1    1      1    0    0     0     0   \n",
       "1      0.360938      0            0       0    0      0    1    0     1     1   \n",
       "2      0.566667      1            1       0    0      0    0    0     0     0   \n",
       "3      0.566667      0            0       1    0      0    0    1     0     0   \n",
       "4      0.700000      0            0       0    0      0    0    0     0     0   \n",
       "...         ...    ...          ...     ...  ...    ...  ...  ...   ...   ...   \n",
       "1559   0.520385      1            1       1    1      1    0    0     0     0   \n",
       "1560   0.404365      0            0       0    0      0    1    1     0     1   \n",
       "1561   0.515714      0            0       0    1      0    1    1     1     1   \n",
       "1562   0.471154      0            0       0    0      0    0    0     0     0   \n",
       "1563   0.497339      0            0       0    1      0    0    1     0     0   \n",
       "\n",
       "      ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  washingtonpost  \\\n",
       "0     ...              0            0            0               0   \n",
       "1     ...              0            0            0               0   \n",
       "2     ...              0            0            0               0   \n",
       "3     ...              0            0            0               0   \n",
       "4     ...              0            0            0               0   \n",
       "...   ...            ...          ...          ...             ...   \n",
       "1559  ...              0            0            0               0   \n",
       "1560  ...              0            0            0               0   \n",
       "1561  ...              0            0            0               0   \n",
       "1562  ...              0            0            0               0   \n",
       "1563  ...              0            0            0               0   \n",
       "\n",
       "      SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  MANASA96592377  cahwerneck  \\\n",
       "0                 0                0          0               0           0   \n",
       "1                 0                0          0               0           0   \n",
       "2                 0                0          0               0           0   \n",
       "3                 0                0          0               0           0   \n",
       "4                 0                0          0               0           0   \n",
       "...             ...              ...        ...             ...         ...   \n",
       "1559              0                0          0               0           0   \n",
       "1560              0                0          0               0           0   \n",
       "1561              0                0          0               0           0   \n",
       "1562              0                0          0               0           0   \n",
       "1563              0                0          0               0           0   \n",
       "\n",
       "      COVIDNewsByMIB  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1559               0  \n",
       "1560               0  \n",
       "1561               0  \n",
       "1562               0  \n",
       "1563               0  \n",
       "\n",
       "[1552 rows x 1159 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_col(df, col):\n",
    "    df_new = df.copy(deep=True)\n",
    "    df_new.drop(col,axis=1,inplace=True)\n",
    "    return df_new\n",
    "\n",
    "train_df_rt_likes = drop_col(train_df_scaled, ['verified'])\n",
    "dev_df_rt_likes = drop_col(dev_df_scaled, ['verified'])\n",
    "test_df_rt_likes = drop_col(test_df_scaled, ['verified'])\n",
    "\n",
    "train_df_rt_verified = drop_col(train_df_scaled, ['likes'])\n",
    "dev_df_rt_verified = drop_col(dev_df_scaled, ['likes'])\n",
    "test_df_rt_verified = drop_col(test_df_scaled, ['likes'])\n",
    "\n",
    "train_df_verified_likes = drop_col(train_df_scaled, ['retweets'])\n",
    "dev_df_verified_likes = drop_col(dev_df_scaled, ['retweets'])\n",
    "test_df_verified_likes = drop_col(test_df_scaled, ['retweets'])\n",
    "\n",
    "\n",
    "train_df_users = drop_col(train_df_scaled, ['retweets','likes','verified'])\n",
    "dev_df_users = drop_col(dev_df_scaled, ['retweets','likes','verified'])\n",
    "test_df_users = drop_col(test_df_scaled, ['retweets','likes','verified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfde0431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>say</th>\n",
       "      <th>like</th>\n",
       "      <th>dont</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 1159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  covid  coronavirus  people  new  virus  get  say  like  dont  \\\n",
       "0      0.586719      1            1       1    1      1    0    0     0     0   \n",
       "1      0.360938      0            0       0    0      0    1    0     1     1   \n",
       "2      0.566667      1            1       0    0      0    0    0     0     0   \n",
       "3      0.566667      0            0       1    0      0    0    1     0     0   \n",
       "4      0.700000      0            0       0    0      0    0    0     0     0   \n",
       "...         ...    ...          ...     ...  ...    ...  ...  ...   ...   ...   \n",
       "1559   0.520385      1            1       1    1      1    0    0     0     0   \n",
       "1560   0.404365      0            0       0    0      0    1    1     0     1   \n",
       "1561   0.515714      0            0       0    1      0    1    1     1     1   \n",
       "1562   0.471154      0            0       0    0      0    0    0     0     0   \n",
       "1563   0.497339      0            0       0    1      0    0    1     0     0   \n",
       "\n",
       "      ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  washingtonpost  \\\n",
       "0     ...              0            0            0               0   \n",
       "1     ...              0            0            0               0   \n",
       "2     ...              0            0            0               0   \n",
       "3     ...              0            0            0               0   \n",
       "4     ...              0            0            0               0   \n",
       "...   ...            ...          ...          ...             ...   \n",
       "1559  ...              0            0            0               0   \n",
       "1560  ...              0            0            0               0   \n",
       "1561  ...              0            0            0               0   \n",
       "1562  ...              0            0            0               0   \n",
       "1563  ...              0            0            0               0   \n",
       "\n",
       "      SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  MANASA96592377  cahwerneck  \\\n",
       "0                 0                0          0               0           0   \n",
       "1                 0                0          0               0           0   \n",
       "2                 0                0          0               0           0   \n",
       "3                 0                0          0               0           0   \n",
       "4                 0                0          0               0           0   \n",
       "...             ...              ...        ...             ...         ...   \n",
       "1559              0                0          0               0           0   \n",
       "1560              0                0          0               0           0   \n",
       "1561              0                0          0               0           0   \n",
       "1562              0                0          0               0           0   \n",
       "1563              0                0          0               0           0   \n",
       "\n",
       "      COVIDNewsByMIB  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1559               0  \n",
       "1560               0  \n",
       "1561               0  \n",
       "1562               0  \n",
       "1563               0  \n",
       "\n",
       "[1552 rows x 1159 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd11b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-733ce4dee759>\", line 18, in <module>\n",
      "    history = model_1000.fit(train_df_rt_likes, y_train, validation_data=(dev_df_rt_likes, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1154, in fit\n",
      "    batch_size=batch_size)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_46_input to have shape (1159,) but got array with shape (1161,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-733ce4dee759>\", line 18, in <module>\n",
      "    history = model_1000.fit(train_df_rt_likes, y_train, validation_data=(dev_df_rt_likes, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1154, in fit\n",
      "    batch_size=batch_size)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_46_input to have shape (1159,) but got array with shape (1161,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-41-733ce4dee759>\", line 18, in <module>\n",
      "    history = model_1000.fit(train_df_rt_likes, y_train, validation_data=(dev_df_rt_likes, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1154, in fit\n",
      "    batch_size=batch_size)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_46_input to have shape (1159,) but got array with shape (1161,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "model_1000 = Sequential()\n",
    "model_1000.add(Dense(1159, activation='relu', input_shape=(1159,)))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(512, activation='relu'))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(128, activation='relu'))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(1, activation='sigmoid'))\n",
    "model_1000.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model_1000.fit(train_df_rt_likes, y_train, validation_data=(dev_df_rt_likes, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
    "_, train_acc = model_1000.evaluate(train_df_rt_likes, y_train, verbose=0)\n",
    "_, test_acc = model_1000.evaluate(dev_df_rt_likes, y_dev, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ff765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-c33d0b622a91>\", line 7, in <module>\n",
      "    predictions_500 = [convert_to_binary(y) for y in model_500.predict(test_df_500)]\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1441, in predict\n",
      "    x, _, _ = self._standardize_user_data(x)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_1_input to have shape (502,) but got array with shape (505,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-c33d0b622a91>\", line 7, in <module>\n",
      "    predictions_500 = [convert_to_binary(y) for y in model_500.predict(test_df_500)]\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1441, in predict\n",
      "    x, _, _ = self._standardize_user_data(x)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_1_input to have shape (502,) but got array with shape (505,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-c33d0b622a91>\", line 7, in <module>\n",
      "    predictions_500 = [convert_to_binary(y) for y in model_500.predict(test_df_500)]\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 1441, in predict\n",
      "    x, _, _ = self._standardize_user_data(x)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py\", line 579, in _standardize_user_data\n",
      "    exception_prefix='input')\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training_utils.py\", line 145, in standardize_input_data\n",
      "    str(data_shape))\n",
      "ValueError: Error when checking input: expected dense_1_input to have shape (502,) but got array with shape (505,)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "def convert_to_binary(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_500 = [convert_to_binary(y) for y in model_500.predict(test_df_500)]\n",
    "predictions_1000 = [convert_to_binary(y) for y in model_1000.predict(test_df_1000)]\n",
    "\n",
    "predictions_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658dcdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-3a665c25d363>\", line 3, in <module>\n",
      "    for i in range(len(predictions_500)):\n",
      "NameError: name 'predictions_500' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 231\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-3a665c25d363>\", line 3, in <module>\n",
      "    for i in range(len(predictions_500)):\n",
      "NameError: name 'predictions_500' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-3a665c25d363>\", line 3, in <module>\n",
      "    for i in range(len(predictions_500)):\n",
      "NameError: name 'predictions_500' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\athet\\.conda\\envs\\NLP\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(predictions_500)):\n",
    "    if predictions_500[i] == predictions_1000[i]:\n",
    "        count+=1\n",
    "        \n",
    "count/len(predictions_500)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceb1c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('y_train.csv', header=True)\n",
    "y_dev.to_csv('y_dev.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09d5c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-estimator==2.1.0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Installing collected packages: tensorflow-estimator\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
      "Successfully installed tensorflow-estimator-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.1.0 requires scipy==1.4.1; python_version >= \"3\", but you have scipy 1.5.2 which is incompatible.\n",
      "tensorflow 2.1.0 requires tensorboard<2.2.0,>=2.1.0, but you have tensorboard 2.4.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-estimator==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49883324",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rt_likes.to_csv('train_df_rt_likes.csv', header=True)\n",
    "dev_df_rt_likes.to_csv('dev_df_rt_likes.csv', header=True)\n",
    "test_df_rt_likes.to_csv('test_df_rt_likes.csv', header=True)\n",
    "\n",
    "train_df_rt_verified.to_csv('train_df_rt_verified.csv', header=True)\n",
    "dev_df_rt_verified.to_csv('dev_df_rt_verified.csv', header=True)\n",
    "test_df_rt_verified.to_csv('test_df_rt_verified.csv', header=True)\n",
    "\n",
    "train_df_verified_likes.to_csv('train_df_verified_likes.csv', header=True)\n",
    "dev_df_verified_likes.to_csv('dev_df_verified_likes.csv', header=True)\n",
    "test_df_verified_likes.to_csv('test_df_verified_likes.csv', header=True)\n",
    "\n",
    "\n",
    "train_df_users.to_csv('train_df_users.csv', header=True)\n",
    "dev_df_users.to_csv('dev_df_users.csv', header=True)\n",
    "test_df_users.to_csv('test_df_users.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39f5fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>say</th>\n",
       "      <th>like</th>\n",
       "      <th>dont</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1552 rows √ó 1159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  covid  coronavirus  people  new  virus  get  say  like  dont  \\\n",
       "0      0.586719      1            1       1    1      1    0    0     0     0   \n",
       "1      0.360938      0            0       0    0      0    1    0     1     1   \n",
       "2      0.566667      1            1       0    0      0    0    0     0     0   \n",
       "3      0.566667      0            0       1    0      0    0    1     0     0   \n",
       "4      0.700000      0            0       0    0      0    0    0     0     0   \n",
       "...         ...    ...          ...     ...  ...    ...  ...  ...   ...   ...   \n",
       "1559   0.520385      1            1       1    1      1    0    0     0     0   \n",
       "1560   0.404365      0            0       0    0      0    1    1     0     1   \n",
       "1561   0.515714      0            0       0    1      0    1    1     1     1   \n",
       "1562   0.471154      0            0       0    0      0    0    0     0     0   \n",
       "1563   0.497339      0            0       0    1      0    0    1     0     0   \n",
       "\n",
       "      ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  washingtonpost  \\\n",
       "0     ...              0            0            0               0   \n",
       "1     ...              0            0            0               0   \n",
       "2     ...              0            0            0               0   \n",
       "3     ...              0            0            0               0   \n",
       "4     ...              0            0            0               0   \n",
       "...   ...            ...          ...          ...             ...   \n",
       "1559  ...              0            0            0               0   \n",
       "1560  ...              0            0            0               0   \n",
       "1561  ...              0            0            0               0   \n",
       "1562  ...              0            0            0               0   \n",
       "1563  ...              0            0            0               0   \n",
       "\n",
       "      SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  MANASA96592377  cahwerneck  \\\n",
       "0                 0                0          0               0           0   \n",
       "1                 0                0          0               0           0   \n",
       "2                 0                0          0               0           0   \n",
       "3                 0                0          0               0           0   \n",
       "4                 0                0          0               0           0   \n",
       "...             ...              ...        ...             ...         ...   \n",
       "1559              0                0          0               0           0   \n",
       "1560              0                0          0               0           0   \n",
       "1561              0                0          0               0           0   \n",
       "1562              0                0          0               0           0   \n",
       "1563              0                0          0               0           0   \n",
       "\n",
       "      COVIDNewsByMIB  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1559               0  \n",
       "1560               0  \n",
       "1561               0  \n",
       "1562               0  \n",
       "1563               0  \n",
       "\n",
       "[1552 rows x 1159 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4fc577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_scaled.to_csv('train_df_scaled.csv', header=True)\n",
    "dev_df_scaled.to_csv('dev_df_scaled.csv', header=True)\n",
    "test_df_scaled.to_csv('test_df_scaled.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c192564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
