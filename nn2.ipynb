{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc4b6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Authentication\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "api_key = \"aJTgi4d1H1zmQNkQuHeualNhP\"\n",
    "api_secrets = \"yPFdp2Bbib25r1iPQCqBuPq8B9UzoJbIdpv1jgzEZFEg1eJl6X\"\n",
    "access_token = \"1409382627124019204-oPpzVGuCwyFfQTfoocFhgHi68whhog\"\n",
    "access_secret = \"esgwpH5gnRfNB0SpiHkO52mZSI5VKKnn8SG2pafEnzj2b\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "\n",
    "TWEET_OBJECT_PATH = 'tweet-objects/'\n",
    "\n",
    " \n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print('Successful Authentication')\n",
    "except:\n",
    "    print('Failed Authentication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ec52f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(filename):\n",
    "    file = open(filename)\n",
    "    threads = file.readlines()\n",
    "    file.close()\n",
    "    return [thread.replace('\\n', '').split(',') for thread in threads]\n",
    "\n",
    "def get_labels(filename):    \n",
    "    file = open(filename)\n",
    "    labels = file.readlines()\n",
    "    file.close()\n",
    "    return [label.replace('\\n', '') for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20c63e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1250219300389974016', '1250219116993974272', '1250219437027766273', '1250219620939657216', '1250219777185873922', '1250219894429208577', '1250219998842216448', '1250220115762667520', '1250220272306638848', '1250220389323526146', '1250220527005753344', '1250220791544705025', '1250220987238383616', '1250221140603047937', '1250221275827470336', '1250221402822545410']\n",
      "\n",
      "nonrumour\n"
     ]
    }
   ],
   "source": [
    "train_ids = get_ids('train.data.txt')\n",
    "train_labels = get_labels('train.label.txt')\n",
    "\n",
    "dev_ids = get_ids('dev.data.txt')\n",
    "dev_labels = get_labels('dev.label.txt')\n",
    "\n",
    "test_ids = get_ids('test.data.txt')\n",
    "\n",
    "print(train_ids[0])\n",
    "print()\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8099fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_ids = [id_ for id_list in train_ids for id_ in id_list]\n",
    "flat_dev_ids = [id_ for id_list in dev_ids for id_ in id_list]\n",
    "flat_test_ids = [id_ for id_list in test_ids for id_ in id_list]\n",
    "\n",
    "unique_ids = list(set(flat_train_ids + flat_dev_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b25b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet id: full text of tweet if found by api, otherwise text from tweet-objects\n",
    "tweets_dict = {}\n",
    "\n",
    "def get_train_tweets_from_api(ids):\n",
    "    for i in range(0, len(ids), 100):\n",
    "        split = ids[i:i+100]\n",
    "        for tweet in api.lookup_statuses(split, tweet_mode='extended'):\n",
    "            tweets_dict[tweet.id_str] = {}\n",
    "            tweets_dict[tweet.id_str]['text'] = tweet.full_text\n",
    "            tweets_dict[tweet.id_str]['user'] = tweet.user.screen_name\n",
    "            tweets_dict[tweet.id_str]['verified'] = tweet.user.verified\n",
    "            tweets_dict[tweet.id_str]['likes'] = tweet.favorite_count\n",
    "            tweets_dict[tweet.id_str]['retweets'] = tweet.retweet_count\n",
    "            \n",
    "def get_test_tweets(ids):\n",
    "    for id_ in ids:\n",
    "        file = open(f'tweet-objects/{id_}.json')\n",
    "        tweet_object = json.load(file)\n",
    "        file.close()\n",
    "        id_str = tweet_object['id_str']\n",
    "        tweets_dict[id_str] = {}\n",
    "        tweets_dict[id_str]['text'] = tweet_object['text']\n",
    "        tweets_dict[id_str]['user'] = tweet_object['user']['screen_name']\n",
    "        tweets_dict[id_str]['verified'] = tweet_object['user']['verified']\n",
    "        tweets_dict[id_str]['likes'] = tweet_object['favorite_count']\n",
    "        tweets_dict[id_str]['retweets'] = tweet_object['retweet_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bd82c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'523589441097433088'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3d54bf73b707>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_test_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_test_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflat_test_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '523589441097433088'"
     ]
    }
   ],
   "source": [
    "get_train_tweets_from_api(unique_ids)\n",
    "get_test_tweets(flat_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "725f116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = []\n",
    "tweet_user = []\n",
    "tweet_verified = []\n",
    "tweet_likes = []\n",
    "tweet_retweets = []\n",
    "\n",
    "for tweet_id in tweets_dict.keys():\n",
    "    tweet_text.append(tweets_dict[tweet_id]['text'])\n",
    "    tweet_user.append(tweets_dict[tweet_id]['user'])\n",
    "    tweet_verified.append(tweets_dict[tweet_id]['verified'])\n",
    "    tweet_likes.append(tweets_dict[tweet_id]['likes'])\n",
    "    tweet_retweets.append(tweets_dict[tweet_id]['retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abff3068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536827853669941248</th>\n",
       "      <td>536827853669941248</td>\n",
       "      <td>Lego letter from the 1970s still offers a powe...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527162917138206721</th>\n",
       "      <td>527162917138206721</td>\n",
       "      <td>@nancyhxxx fuck my lyfe</td>\n",
       "      <td>HayleyMadss</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537699056806809600</th>\n",
       "      <td>537699056806809600</td>\n",
       "      <td>@PoloT_TreyG I don't believe it, I want an art...</td>\n",
       "      <td>lenihan16</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532297249838354432</th>\n",
       "      <td>532297249838354432</td>\n",
       "      <td>@nypost HA I tell my sons all the time, \"this ...</td>\n",
       "      <td>RetiredAtFour4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539285886995660803</th>\n",
       "      <td>539285886995660803</td>\n",
       "      <td>@AbbyMartin @PamelaDrew @senorchompers Promine...</td>\n",
       "      <td>ChuckNoyes</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222929611232817159</th>\n",
       "      <td>1222929611232817159</td>\n",
       "      <td>@crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...</td>\n",
       "      <td>96incognito69</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222944075826884608</th>\n",
       "      <td>1222944075826884608</td>\n",
       "      <td>@WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...</td>\n",
       "      <td>ellenli_lxw</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324381215707139</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>Can CoVID-19 be caught from a person who has n...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324383396716546</th>\n",
       "      <td>1239324383396716546</td>\n",
       "      <td>However, many people with #COVID-19 experience...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239324385707687938</th>\n",
       "      <td>1239324385707687938</td>\n",
       "      <td>@WHO is assessing ongoing research on the peri...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34141 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "536827853669941248    536827853669941248   \n",
       "527162917138206721    527162917138206721   \n",
       "537699056806809600    537699056806809600   \n",
       "532297249838354432    532297249838354432   \n",
       "539285886995660803    539285886995660803   \n",
       "...                                  ...   \n",
       "1222929611232817159  1222929611232817159   \n",
       "1222944075826884608  1222944075826884608   \n",
       "1239324381215707139  1239324381215707139   \n",
       "1239324383396716546  1239324383396716546   \n",
       "1239324385707687938  1239324385707687938   \n",
       "\n",
       "                                                                  text  \\\n",
       "536827853669941248   Lego letter from the 1970s still offers a powe...   \n",
       "527162917138206721                             @nancyhxxx fuck my lyfe   \n",
       "537699056806809600   @PoloT_TreyG I don't believe it, I want an art...   \n",
       "532297249838354432   @nypost HA I tell my sons all the time, \"this ...   \n",
       "539285886995660803   @AbbyMartin @PamelaDrew @senorchompers Promine...   \n",
       "...                                                                ...   \n",
       "1222929611232817159  @crbabecrab @WHO @DrTedros @WHOWPRO @WHOSEARO ...   \n",
       "1222944075826884608  @WHO @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe ...   \n",
       "1239324381215707139  Can CoVID-19 be caught from a person who has n...   \n",
       "1239324383396716546  However, many people with #COVID-19 experience...   \n",
       "1239324385707687938  @WHO is assessing ongoing research on the peri...   \n",
       "\n",
       "                               user  verified  likes  retweets  \n",
       "536827853669941248      Independent      True    186       235  \n",
       "527162917138206721      HayleyMadss     False      1         0  \n",
       "537699056806809600        lenihan16     False      0         0  \n",
       "532297249838354432   RetiredAtFour4     False      0         0  \n",
       "539285886995660803       ChuckNoyes     False      3         2  \n",
       "...                             ...       ...    ...       ...  \n",
       "1222929611232817159   96incognito69     False      4         0  \n",
       "1222944075826884608     ellenli_lxw     False      1         0  \n",
       "1239324381215707139   mugabo_robert     False      1         1  \n",
       "1239324383396716546   mugabo_robert     False      1         1  \n",
       "1239324385707687938   mugabo_robert     False      1         1  \n",
       "\n",
       "[34141 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids_df = pd.DataFrame({'id': tweets_dict.keys(), \n",
    "                             'text': tweet_text, \n",
    "                             'user': tweet_user,\n",
    "                             'verified': tweet_verified,\n",
    "                             'likes': tweet_likes,\n",
    "                             'retweets': tweet_retweets},\n",
    "                              index=tweets_dict.keys())\n",
    "tweet_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17bfcf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mugabo_robert'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.get_status('1239324385707687938').user.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7d3186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids_df.to_csv('tweets_id_text.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9681c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536827853669941248</th>\n",
       "      <td>536827853669941248</td>\n",
       "      <td>Lego letter from the 1970s still offers a powe...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527162917138206721</th>\n",
       "      <td>527162917138206721</td>\n",
       "      <td>@nancyhxxx fuck my lyfe</td>\n",
       "      <td>HayleyMadss</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537699056806809600</th>\n",
       "      <td>537699056806809600</td>\n",
       "      <td>@PoloT_TreyG I don't believe it, I want an art...</td>\n",
       "      <td>lenihan16</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532297249838354432</th>\n",
       "      <td>532297249838354432</td>\n",
       "      <td>@nypost HA I tell my sons all the time, \"this ...</td>\n",
       "      <td>RetiredAtFour4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539285886995660803</th>\n",
       "      <td>539285886995660803</td>\n",
       "      <td>@AbbyMartin @PamelaDrew @senorchompers Promine...</td>\n",
       "      <td>ChuckNoyes</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "536827853669941248  536827853669941248   \n",
       "527162917138206721  527162917138206721   \n",
       "537699056806809600  537699056806809600   \n",
       "532297249838354432  532297249838354432   \n",
       "539285886995660803  539285886995660803   \n",
       "\n",
       "                                                                 text  \\\n",
       "536827853669941248  Lego letter from the 1970s still offers a powe...   \n",
       "527162917138206721                            @nancyhxxx fuck my lyfe   \n",
       "537699056806809600  @PoloT_TreyG I don't believe it, I want an art...   \n",
       "532297249838354432  @nypost HA I tell my sons all the time, \"this ...   \n",
       "539285886995660803  @AbbyMartin @PamelaDrew @senorchompers Promine...   \n",
       "\n",
       "                              user  verified  likes  retweets  \n",
       "536827853669941248     Independent      True    186       235  \n",
       "527162917138206721     HayleyMadss     False      1         0  \n",
       "537699056806809600       lenihan16     False      0         0  \n",
       "532297249838354432  RetiredAtFour4     False      0         0  \n",
       "539285886995660803      ChuckNoyes     False      3         2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids_df = pd.read_csv('tweets_id_text.csv', index_col=0) \n",
    "tweet_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0c1930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    # rumour: 1, nonrumour: 0\n",
    "    if label == 'rumour':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def concatenate_tweets(source, reply_ids):\n",
    "    concat = source\n",
    "    \n",
    "    for id_ in reply_ids:\n",
    "        try:\n",
    "            tweet = tweet_ids_df.loc[int(id_), 'text'] # may throw key error\n",
    "            concat += ' ' + tweet\n",
    "        except:\n",
    "            continue\n",
    "    concat = concat.strip()\n",
    "    \n",
    "    return concat\n",
    "\n",
    "\n",
    "def create_dataframe(ids, labs, include_labels=True):\n",
    "    source_ids = []\n",
    "    reply_ids_list = []\n",
    "    concat_tweets = []\n",
    "    users = []\n",
    "    verified = []\n",
    "    likes = []\n",
    "    retweets = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        # add concatenation of source and reply tweets to concat_tweets\n",
    "        try:\n",
    "            source = tweet_ids_df.loc[int(ids[i][0]), 'text'] # may throw key error\n",
    "            if len(ids[i]) > 1:\n",
    "                concat = concatenate_tweets(source, ids[i][1:])\n",
    "            concat_tweets.append(concat)\n",
    "            users.append(tweet_ids_df.loc[int(ids[i][0]), 'user'])\n",
    "            verified.append(tweet_ids_df.loc[int(ids[i][0]), 'verified'])\n",
    "            likes.append(tweet_ids_df.loc[int(ids[i][0]), 'likes'])\n",
    "            retweets.append(tweet_ids_df.loc[int(ids[i][0]), 'retweets'])\n",
    "        except:\n",
    "            if include_labels:\n",
    "                continue # skip instance if source tweet is missing\n",
    "            else:\n",
    "                concat_tweets.append('')\n",
    "\n",
    "        # add id of source tweet to source_ids\n",
    "        source_ids.append(ids[i][0])\n",
    "\n",
    "        # add list of ids of reply tweets to reply_ids_list if there are replies\n",
    "        if len(ids[i]) > 1:\n",
    "            reply_ids_list.append(ids[i][1:])\n",
    "        else:\n",
    "            reply_ids_list.append([])              \n",
    "\n",
    "        if include_labels:\n",
    "            # add encoded label to labels (1 for rumour, 0 for nonrumour)\n",
    "            label = encode_label(labs[i])\n",
    "            labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame({'source_id': source_ids, \n",
    "                       'reply_ids': reply_ids_list,\n",
    "                       'concat_tweet': concat_tweets,\n",
    "                       'user': users, \n",
    "                       'verified': verified,\n",
    "                       'likes': likes,\n",
    "                       'retweets': retweets})\n",
    "    \n",
    "    if include_labels:\n",
    "        df['label'] = labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4ef5ea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250219300389974016</td>\n",
       "      <td>[1250219116993974272, 1250219437027766273, 125...</td>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>554886875303780352</td>\n",
       "      <td>[554894001946759168, 554959644125167617, 55492...</td>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237901309011021825</td>\n",
       "      <td>[1237901311439450112, 1239862502516760577]</td>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524958128392376320</td>\n",
       "      <td>[524961934064754688, 524959028061798401, 52495...</td>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239295488677085185</td>\n",
       "      <td>[1239562248990806016]</td>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id                                          reply_ids  \\\n",
       "0  1250219300389974016  [1250219116993974272, 1250219437027766273, 125...   \n",
       "1   554886875303780352  [554894001946759168, 554959644125167617, 55492...   \n",
       "2  1237901309011021825         [1237901311439450112, 1239862502516760577]   \n",
       "3   524958128392376320  [524961934064754688, 524959028061798401, 52495...   \n",
       "4  1239295488677085185                              [1239562248990806016]   \n",
       "\n",
       "                                        concat_tweet             user  \\\n",
       "0  5. Can regularly rinsing your nose with saline...        ucoptempe   \n",
       "1  French police chief killed himself after #Char...        Telegraph   \n",
       "2  Coronavirus disease (COVID-19) advice for the ...  kareem_alnakeeb   \n",
       "3  Ottawa police confirm that there were multiple...              WSJ   \n",
       "4  if the primary focus of a government isn't to ...     hoss_bossman   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0     False      0         0      0  \n",
       "1      True     43       184      1  \n",
       "2     False      4         1      0  \n",
       "3      True     23       120      0  \n",
       "4     False      6         1      0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = create_dataframe(train_ids, train_labels)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8b18993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249004694950817796</td>\n",
       "      <td>[1249011200068730880]</td>\n",
       "      <td>COVID-19 Fact:\\nAre hand dryers effective in k...</td>\n",
       "      <td>WeatherBug</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267552274819227649</td>\n",
       "      <td>[1270394169836568576, 1270502071175909376]</td>\n",
       "      <td>@atruchecks when can we expect the result of m...</td>\n",
       "      <td>ewart_lynne</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235238334722699265</td>\n",
       "      <td>[1235234904281165825, 1235234927937048577, 123...</td>\n",
       "      <td>How does COVID-19 spread? \\n\\nPeople can catch...</td>\n",
       "      <td>Agali_GCFR</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1248746792914546688</td>\n",
       "      <td>[1248775858120097792]</td>\n",
       "      <td>every news outlet using headlines like,\\n\\n\"ar...</td>\n",
       "      <td>TuckyAalto</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523820806917603328</td>\n",
       "      <td>[523943560589361152, 524027059346370560, 53048...</td>\n",
       "      <td>Researcher @naskrecki on his encounter with a ...</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id                                          reply_ids  \\\n",
       "0  1249004694950817796                              [1249011200068730880]   \n",
       "1  1267552274819227649         [1270394169836568576, 1270502071175909376]   \n",
       "2  1235238334722699265  [1235234904281165825, 1235234927937048577, 123...   \n",
       "3  1248746792914546688                              [1248775858120097792]   \n",
       "4   523820806917603328  [523943560589361152, 524027059346370560, 53048...   \n",
       "\n",
       "                                        concat_tweet         user  verified  \\\n",
       "0  COVID-19 Fact:\\nAre hand dryers effective in k...   WeatherBug     False   \n",
       "1  @atruchecks when can we expect the result of m...  ewart_lynne     False   \n",
       "2  How does COVID-19 spread? \\n\\nPeople can catch...   Agali_GCFR     False   \n",
       "3  every news outlet using headlines like,\\n\\n\"ar...   TuckyAalto     False   \n",
       "4  Researcher @naskrecki on his encounter with a ...      Harvard      True   \n",
       "\n",
       "   likes  retweets  label  \n",
       "0      6         1      0  \n",
       "1      0         0      0  \n",
       "2      0         0      0  \n",
       "3     17         0      0  \n",
       "4     71       149      0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_full_df = create_dataframe(dev_ids, dev_labels)\n",
    "dev_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd655731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>reply_ids</th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1246482832316301319</td>\n",
       "      <td>[1247355493988909056]</td>\n",
       "      <td>How Does COVID-19 Spread? https://t.co/TXHDeUp...</td>\n",
       "      <td>WCCO</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1252279738099433473</td>\n",
       "      <td>[1251884146403815428, 1252033306100670464, 125...</td>\n",
       "      <td>@brain_warrior I hate to keep saying it, but C...</td>\n",
       "      <td>Kikasitsu</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1236050255394877440</td>\n",
       "      <td>[1236050046950481922, 1236050331940855808]</td>\n",
       "      <td>Q. How are COVID-19 and influenza viruses diff...</td>\n",
       "      <td>CovidIreland</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1235582115900796928</td>\n",
       "      <td>[1235584239497867275, 1235585067973578752, 123...</td>\n",
       "      <td>Una de les Q&amp;amp;A on coronaviruses de la pàgi...</td>\n",
       "      <td>PerePuigUAB</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1258787515592572928</td>\n",
       "      <td>[1258710626676899840, 1258711444075565058, 125...</td>\n",
       "      <td>@_truthpolitics We should absolutely blame the...</td>\n",
       "      <td>klarth</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>427944719612915712</td>\n",
       "      <td>[427960532981665792, 427949634032783360, 42794...</td>\n",
       "      <td>Ex-Marlboro man dies from smoking-related dise...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>531206167302012929</td>\n",
       "      <td>[531228826496679936, 531255748157005825, 53120...</td>\n",
       "      <td>Holy shit. Doritos flavored Mountain Dew.\\n\\nA...</td>\n",
       "      <td>Boogie2988</td>\n",
       "      <td>True</td>\n",
       "      <td>342</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>553099685888790528</td>\n",
       "      <td>[553640547282608128, 557627319322685441, 55310...</td>\n",
       "      <td>Banksy account joins cartoonists support for #...</td>\n",
       "      <td>ThePoke</td>\n",
       "      <td>True</td>\n",
       "      <td>230</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1222928724112396288</td>\n",
       "      <td>[1222922750546923521, 1222929006967869442, 122...</td>\n",
       "      <td>@DrTedros @WHOWPRO @WHOSEARO @WHO_Europe @paho...</td>\n",
       "      <td>WHO</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1239324381215707139</td>\n",
       "      <td>[1239324383396716546, 1239324385707687938]</td>\n",
       "      <td>Can CoVID-19 be caught from a person who has n...</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source_id                                          reply_ids  \\\n",
       "0    1246482832316301319                              [1247355493988909056]   \n",
       "1    1252279738099433473  [1251884146403815428, 1252033306100670464, 125...   \n",
       "2    1236050255394877440         [1236050046950481922, 1236050331940855808]   \n",
       "3    1235582115900796928  [1235584239497867275, 1235585067973578752, 123...   \n",
       "4    1258787515592572928  [1258710626676899840, 1258711444075565058, 125...   \n",
       "..                   ...                                                ...   \n",
       "553   427944719612915712  [427960532981665792, 427949634032783360, 42794...   \n",
       "554   531206167302012929  [531228826496679936, 531255748157005825, 53120...   \n",
       "555   553099685888790528  [553640547282608128, 557627319322685441, 55310...   \n",
       "556  1222928724112396288  [1222922750546923521, 1222929006967869442, 122...   \n",
       "557  1239324381215707139         [1239324383396716546, 1239324385707687938]   \n",
       "\n",
       "                                          concat_tweet            user  \\\n",
       "0    How Does COVID-19 Spread? https://t.co/TXHDeUp...            WCCO   \n",
       "1    @brain_warrior I hate to keep saying it, but C...       Kikasitsu   \n",
       "2    Q. How are COVID-19 and influenza viruses diff...    CovidIreland   \n",
       "3    Una de les Q&amp;A on coronaviruses de la pàgi...     PerePuigUAB   \n",
       "4    @_truthpolitics We should absolutely blame the...          klarth   \n",
       "..                                                 ...             ...   \n",
       "553  Ex-Marlboro man dies from smoking-related dise...  washingtonpost   \n",
       "554  Holy shit. Doritos flavored Mountain Dew.\\n\\nA...      Boogie2988   \n",
       "555  Banksy account joins cartoonists support for #...         ThePoke   \n",
       "556  @DrTedros @WHOWPRO @WHOSEARO @WHO_Europe @paho...             WHO   \n",
       "557  Can CoVID-19 be caught from a person who has n...   mugabo_robert   \n",
       "\n",
       "     verified  likes  retweets  \n",
       "0        True      4         0  \n",
       "1       False      0         0  \n",
       "2       False      2         0  \n",
       "3       False      3         4  \n",
       "4       False      0         0  \n",
       "..        ...    ...       ...  \n",
       "553      True     26       139  \n",
       "554      True    342       181  \n",
       "555      True    230       350  \n",
       "556      True     47        19  \n",
       "557     False      1         1  \n",
       "\n",
       "[558 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_df = create_dataframe(test_ids, None, include_labels=False)\n",
    "test_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13b24c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French police chief killed himself after #Char...</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease (COVID-19) advice for the ...</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        concat_tweet             user  \\\n",
       "0  5. Can regularly rinsing your nose with saline...        ucoptempe   \n",
       "1  French police chief killed himself after #Char...        Telegraph   \n",
       "2  Coronavirus disease (COVID-19) advice for the ...  kareem_alnakeeb   \n",
       "3  Ottawa police confirm that there were multiple...              WSJ   \n",
       "4  if the primary focus of a government isn't to ...     hoss_bossman   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0     False      0         0      0  \n",
       "1      True     43       184      1  \n",
       "2     False      4         1      0  \n",
       "3      True     23       120      0  \n",
       "4     False      6         1      0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "dev_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "test_full_df.drop(['source_id','reply_ids'],axis=1,inplace=True)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "adbf1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    preprocessed = df\n",
    "    text = list(preprocessed['concat_tweet'])\n",
    "    verified = list(preprocessed['verified'])\n",
    "    sentiment = []\n",
    "    for i in range(len(text)):\n",
    "        text[i] = \" \".join(filter(lambda x:x[0]!='@', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:4]!='http', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:4]!='&amp', text[i].split()))\n",
    "        text[i] = re.sub(r'[^a-zA-Z ]','',text[i])\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:1]!='Q', text[i].split()))\n",
    "        text[i] = \" \".join(filter(lambda x:x[0:1]!='A', text[i].split()))\n",
    "        sentiment.append(TextBlob(text[i]).sentiment.polarity)\n",
    "    preprocessed['concat_tweet'] = text\n",
    "    for j in range(len(verified)):\n",
    "        if verified[j]:\n",
    "            verified[j] = 1\n",
    "        else:\n",
    "            verified[j] = 0\n",
    "    preprocessed['verified'] = verified\n",
    "    preprocessed.insert(1, 'sentiment',sentiment)\n",
    "    preprocessed.fillna('', inplace=True)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8329e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can regularly rinsing your nose with saline he...</td>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French police chief killed himself after Charl...</td>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus disease COVID advice for the publi...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ottawa police confirm that there were multiple...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the primary focus of a government isnt to a...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>It cannot be transmitted through goods manufac...</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>sattykrosse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>Desperate Ted Cruz Claims Planned Parenthood S...</td>\n",
       "      <td>-0.191270</td>\n",
       "      <td>Bipartisanism</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>Thoughts and prayers are not enough Pres Obama...</td>\n",
       "      <td>0.031427</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>Police have surrounded this building where the...</td>\n",
       "      <td>-0.057692</td>\n",
       "      <td>NBCNews</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>I can help am Socialism what is it and why do ...</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>rosierawle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           concat_tweet  sentiment  \\\n",
       "0     Can regularly rinsing your nose with saline he...   0.173437   \n",
       "1     French police chief killed himself after Charl...  -0.278125   \n",
       "2     Coronavirus disease COVID advice for the publi...   0.133333   \n",
       "3     Ottawa police confirm that there were multiple...   0.133333   \n",
       "4     if the primary focus of a government isnt to a...   0.400000   \n",
       "...                                                 ...        ...   \n",
       "1560  It cannot be transmitted through goods manufac...   0.040770   \n",
       "1561  Desperate Ted Cruz Claims Planned Parenthood S...  -0.191270   \n",
       "1562  Thoughts and prayers are not enough Pres Obama...   0.031427   \n",
       "1563  Police have surrounded this building where the...  -0.057692   \n",
       "1564  I can help am Socialism what is it and why do ...  -0.005323   \n",
       "\n",
       "                 user  verified  likes  retweets  label  \n",
       "0           ucoptempe         0      0         0      0  \n",
       "1           Telegraph         1     43       184      1  \n",
       "2     kareem_alnakeeb         0      4         1      0  \n",
       "3                 WSJ         1     23       120      0  \n",
       "4        hoss_bossman         0      6         1      0  \n",
       "...               ...       ...    ...       ...    ...  \n",
       "1560      sattykrosse         0      0         0      0  \n",
       "1561    Bipartisanism         1     56        76      1  \n",
       "1562              ABC         1    148       108      1  \n",
       "1563          NBCNews         1     63       176      0  \n",
       "1564       rosierawle         0      0         0      0  \n",
       "\n",
       "[1553 rows x 7 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = preprocess_df(train_full_df)\n",
    "train_full_df.drop_duplicates(subset=['concat_tweet'][0:100],inplace=True)\n",
    "\n",
    "dev_full_df = preprocess_df(dev_full_df)\n",
    "dev_full_df.drop_duplicates(subset=['concat_tweet'][0:100],inplace=True)\n",
    "\n",
    "test_full_df = preprocess_df(test_full_df)\n",
    "train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d1e26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english')) #note: stopwords are all in lowercase\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def tokenize_df(df):\n",
    "    tokenized_df = df\n",
    "    tokenized_sentence = []\n",
    "    for _id, row in tokenized_df.iterrows():\n",
    "        text = row['concat_tweet']\n",
    "        # tokenize tweet\n",
    "        tokens = tt.tokenize(text)\n",
    "        # convert to lowercase\n",
    "        tokens = [tok.lower() for tok in tokens]\n",
    "        # remove stopwords\n",
    "        tokens = [tok for tok in tokens if tok not in stopwords]\n",
    "        # lemmatize\n",
    "        tokens = [lemmatize(tok) for tok in tokens]\n",
    "        tokenized_sentence.append(tokens)\n",
    "    tokenized_df.insert(1, 'tokens', tokenized_sentence)\n",
    "    tokenized_df.drop('concat_tweet',axis=1,inplace=True)\n",
    "    return tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9c3f1b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[regularly, rinse, nose, saline, help, prevent...</td>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[french, police, chief, kill, charliehebdo, at...</td>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[coronavirus, disease, covid, advice, public, ...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ottawa, police, confirm, multiple, suspect, s...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[primary, focus, government, isnt, alleviate, ...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  sentiment  \\\n",
       "0  [regularly, rinse, nose, saline, help, prevent...   0.173437   \n",
       "1  [french, police, chief, kill, charliehebdo, at...  -0.278125   \n",
       "2  [coronavirus, disease, covid, advice, public, ...   0.133333   \n",
       "3  [ottawa, police, confirm, multiple, suspect, s...   0.133333   \n",
       "4  [primary, focus, government, isnt, alleviate, ...   0.400000   \n",
       "\n",
       "              user  verified  likes  retweets  label  \n",
       "0        ucoptempe         0      0         0      0  \n",
       "1        Telegraph         1     43       184      1  \n",
       "2  kareem_alnakeeb         0      4         1      0  \n",
       "3              WSJ         1     23       120      0  \n",
       "4     hoss_bossman         0      6         1      0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_df = tokenize_df(train_full_df)\n",
    "train_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "91b635dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[covid, fact, hand, dryer, effective, kill, ne...</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>WeatherBug</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[expect, result, husband, pendingantibody, tes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ewart_lynne</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[covid, spread, people, catch, covid, others, ...</td>\n",
       "      <td>0.026257</td>\n",
       "      <td>Agali_GCFR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[every, news, outlet, use, headline, like, ant...</td>\n",
       "      <td>-0.056439</td>\n",
       "      <td>TuckyAalto</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[researcher, encounter, goliath, birdeater, wo...</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  sentiment         user  \\\n",
       "0  [covid, fact, hand, dryer, effective, kill, ne...   0.484091   WeatherBug   \n",
       "1  [expect, result, husband, pendingantibody, tes...   0.000000  ewart_lynne   \n",
       "2  [covid, spread, people, catch, covid, others, ...   0.026257   Agali_GCFR   \n",
       "3  [every, news, outlet, use, headline, like, ant...  -0.056439   TuckyAalto   \n",
       "4  [researcher, encounter, goliath, birdeater, wo...   0.168182      Harvard   \n",
       "\n",
       "   verified  likes  retweets  label  \n",
       "0         0      6         1      0  \n",
       "1         0      0         0      0  \n",
       "2         0      0         0      0  \n",
       "3         0     17         0      0  \n",
       "4         1     71       149      0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_full_df = tokenize_df(dev_full_df)\n",
    "dev_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de35c2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[covid, spread, thank, wcco, station, trust, m...</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>WCCO</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hate, keep, say, capitalism, implode, without...</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>Kikasitsu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[covid, influenza, virus, different, covid, co...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>CovidIreland</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[una, de, le, coronaviruses, de, la, pgina, we...</td>\n",
       "      <td>0.068466</td>\n",
       "      <td>PerePuigUAB</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[absolutely, blame, politician, whoever, else,...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>klarth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>[exmarlboro, man, die, smokingrelated, disease...</td>\n",
       "      <td>0.174937</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>[holy, shit, doritos, flavor, mountain, dew, l...</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>Boogie2988</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[banksy, account, join, cartoonist, support, c...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>ThePoke</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[member, international, heal, member, adviser,...</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>WHO</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>[covid, catch, person, symptom, main, way, dis...</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>mugabo_robert</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  sentiment  \\\n",
       "0    [covid, spread, thank, wcco, station, trust, m...   0.183333   \n",
       "1    [hate, keep, say, capitalism, implode, without...  -0.160000   \n",
       "2    [covid, influenza, virus, different, covid, co...   0.100000   \n",
       "3    [una, de, le, coronaviruses, de, la, pgina, we...   0.068466   \n",
       "4    [absolutely, blame, politician, whoever, else,...   0.333333   \n",
       "..                                                 ...        ...   \n",
       "553  [exmarlboro, man, die, smokingrelated, disease...   0.174937   \n",
       "554  [holy, shit, doritos, flavor, mountain, dew, l...   0.043953   \n",
       "555  [banksy, account, join, cartoonist, support, c...   0.083333   \n",
       "556  [member, international, heal, member, adviser,...   0.233333   \n",
       "557  [covid, catch, person, symptom, main, way, dis...   0.241667   \n",
       "\n",
       "               user  verified  likes  retweets  \n",
       "0              WCCO         1      4         0  \n",
       "1         Kikasitsu         0      0         0  \n",
       "2      CovidIreland         0      2         0  \n",
       "3       PerePuigUAB         0      3         4  \n",
       "4            klarth         0      0         0  \n",
       "..              ...       ...    ...       ...  \n",
       "553  washingtonpost         1     26       139  \n",
       "554      Boogie2988         1    342       181  \n",
       "555         ThePoke         1    230       350  \n",
       "556             WHO         1     47        19  \n",
       "557   mugabo_robert         0      1         1  \n",
       "\n",
       "[558 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_df = tokenize_df(test_full_df)\n",
    "test_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "964e0e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 2249,\n",
       " 'coronavirus': 1899,\n",
       " 'people': 1638,\n",
       " 'new': 1556,\n",
       " 'virus': 1071,\n",
       " 'get': 865,\n",
       " 'say': 785,\n",
       " 'like': 783,\n",
       " 'dont': 645,\n",
       " 'prevent': 607,\n",
       " 'make': 589,\n",
       " 'know': 582,\n",
       " 'go': 580,\n",
       " 'kill': 577,\n",
       " 'spread': 550,\n",
       " 'one': 535,\n",
       " 'take': 533,\n",
       " 'think': 528,\n",
       " 'need': 519,\n",
       " 'see': 509,\n",
       " 'u': 495,\n",
       " 'disease': 481,\n",
       " 'would': 474,\n",
       " 'hand': 473,\n",
       " 'rt': 447,\n",
       " 'good': 444,\n",
       " 'test': 442,\n",
       " 'person': 430,\n",
       " 'symptom': 419,\n",
       " 'protect': 411,\n",
       " 'time': 407,\n",
       " 'infect': 398,\n",
       " 'use': 396,\n",
       " 'infection': 388,\n",
       " 'im': 381,\n",
       " 'help': 372,\n",
       " 'may': 371,\n",
       " 'thats': 363,\n",
       " 'spider': 361,\n",
       " 'day': 360,\n",
       " 'die': 351,\n",
       " 'effective': 348,\n",
       " 'work': 346,\n",
       " 'case': 337,\n",
       " 'cough': 336,\n",
       " 'give': 335,\n",
       " 'cause': 326,\n",
       " 'death': 317,\n",
       " 'want': 315,\n",
       " 'someone': 314,\n",
       " 'treat': 311,\n",
       " 'report': 310,\n",
       " 'mask': 306,\n",
       " 'look': 304,\n",
       " 'wear': 302,\n",
       " 'come': 302,\n",
       " 'shoot': 300,\n",
       " 'catch': 298,\n",
       " 'transmit': 295,\n",
       " 'also': 293,\n",
       " 'still': 282,\n",
       " 'way': 278,\n",
       " 'even': 278,\n",
       " 'nose': 276,\n",
       " 'thank': 274,\n",
       " 'find': 269,\n",
       " 'right': 269,\n",
       " 'vaccine': 268,\n",
       " 'china': 267,\n",
       " 'world': 265,\n",
       " 'mean': 262,\n",
       " 'health': 260,\n",
       " 'news': 260,\n",
       " 'woman': 259,\n",
       " 'well': 255,\n",
       " 'ncov': 251,\n",
       " 'really': 249,\n",
       " 'hot': 248,\n",
       " 'thing': 244,\n",
       " 'many': 244,\n",
       " 'home': 243,\n",
       " 'antibiotic': 241,\n",
       " 'stop': 238,\n",
       " 'care': 237,\n",
       " 'country': 237,\n",
       " 'much': 237,\n",
       " 'live': 235,\n",
       " 'first': 233,\n",
       " 'eat': 229,\n",
       " 'become': 229,\n",
       " 'droplet': 229,\n",
       " 'call': 226,\n",
       " 'show': 226,\n",
       " 'puppysized': 225,\n",
       " 'safe': 222,\n",
       " 'could': 221,\n",
       " 'please': 221,\n",
       " 'spray': 220,\n",
       " 'fact': 220,\n",
       " 'body': 219,\n",
       " 'respiratory': 218,\n",
       " 'scientist': 217,\n",
       " 'stay': 215,\n",
       " 'water': 215,\n",
       " 'lol': 212,\n",
       " 'paul': 212,\n",
       " 'tell': 210,\n",
       " 'evidence': 209,\n",
       " 'love': 209,\n",
       " 'follow': 207,\n",
       " 'walker': 207,\n",
       " 'police': 206,\n",
       " 'year': 206,\n",
       " 'break': 206,\n",
       " 'oh': 205,\n",
       " 'man': 205,\n",
       " 'let': 204,\n",
       " 'surprise': 201,\n",
       " 'cant': 200,\n",
       " 'put': 198,\n",
       " 'god': 198,\n",
       " 'part': 198,\n",
       " 'sad': 196,\n",
       " 'rainforest': 196,\n",
       " 'specific': 195,\n",
       " 'try': 192,\n",
       " 'risk': 192,\n",
       " 'yes': 192,\n",
       " 'immunity': 192,\n",
       " 'president': 191,\n",
       " 'fuck': 185,\n",
       " 'around': 184,\n",
       " 'feel': 183,\n",
       " 'million': 181,\n",
       " 'medical': 181,\n",
       " 'rip': 180,\n",
       " 'medicine': 180,\n",
       " 'true': 180,\n",
       " 'affect': 179,\n",
       " 'sick': 179,\n",
       " 'food': 179,\n",
       " 'white': 178,\n",
       " 'flu': 178,\n",
       " 'cannot': 177,\n",
       " 'older': 177,\n",
       " 'confirm': 176,\n",
       " 'touch': 175,\n",
       " 'happen': 174,\n",
       " 'area': 172,\n",
       " 'la': 172,\n",
       " 'family': 172,\n",
       " 'fever': 172,\n",
       " 'surface': 171,\n",
       " 'garlic': 170,\n",
       " 'everyone': 170,\n",
       " 'g': 169,\n",
       " 'big': 169,\n",
       " 'iphone': 169,\n",
       " 'sure': 168,\n",
       " 'florida': 168,\n",
       " 'complexmag': 167,\n",
       " 'however': 166,\n",
       " 'number': 165,\n",
       " 'myth': 165,\n",
       " 'third': 165,\n",
       " 'doesnt': 164,\n",
       " 'long': 164,\n",
       " 'better': 163,\n",
       " 'include': 163,\n",
       " 'wash': 163,\n",
       " 'guy': 162,\n",
       " 'mouth': 162,\n",
       " 'human': 161,\n",
       " 'great': 161,\n",
       " 'believe': 160,\n",
       " 'keep': 159,\n",
       " 'develop': 157,\n",
       " 'dead': 156,\n",
       " 'alcohol': 155,\n",
       " 'back': 155,\n",
       " 'obama': 155,\n",
       " 'didnt': 154,\n",
       " 'real': 153,\n",
       " 'life': 153,\n",
       " 'last': 153,\n",
       " 'cold': 151,\n",
       " 'contact': 149,\n",
       " 'breathe': 149,\n",
       " 'read': 147,\n",
       " 'city': 147,\n",
       " 'date': 146,\n",
       " 'hope': 145,\n",
       " 'result': 145,\n",
       " 'without': 142,\n",
       " 'soldier': 142,\n",
       " 'pocket': 142,\n",
       " 'herd': 142,\n",
       " 'team': 142,\n",
       " 'treatment': 141,\n",
       " 'ill': 141,\n",
       " 'add': 140,\n",
       " 'bend': 140,\n",
       " 'regularly': 139,\n",
       " 'pneumonia': 139,\n",
       " 'word': 138,\n",
       " 'question': 137,\n",
       " 'wont': 137,\n",
       " 'yet': 137,\n",
       " 'seem': 137,\n",
       " 'buzzfeed': 136,\n",
       " 'house': 135,\n",
       " 'public': 134,\n",
       " 'outbreak': 134,\n",
       " 'air': 134,\n",
       " 'source': 134,\n",
       " 'never': 134,\n",
       " 'others': 133,\n",
       " 'animal': 133,\n",
       " 'dew': 133,\n",
       " 'pay': 131,\n",
       " 'watch': 131,\n",
       " 'vega': 130,\n",
       " 'fast': 129,\n",
       " 'south': 129,\n",
       " 'two': 129,\n",
       " 'receive': 129,\n",
       " 'do': 129,\n",
       " 'wow': 127,\n",
       " 'state': 127,\n",
       " 'hostage': 127,\n",
       " 'mountain': 127,\n",
       " 'expansion': 127,\n",
       " 'weather': 126,\n",
       " 'government': 126,\n",
       " 'place': 126,\n",
       " 'ask': 126,\n",
       " 'update': 125,\n",
       " 'hear': 125,\n",
       " 'dog': 125,\n",
       " 'problem': 124,\n",
       " 'penis': 123,\n",
       " 'talk': 123,\n",
       " 'photo': 123,\n",
       " 'clean': 122,\n",
       " 'leave': 122,\n",
       " 'information': 122,\n",
       " 'buy': 122,\n",
       " 'shit': 120,\n",
       " 'war': 120,\n",
       " 'age': 120,\n",
       " 'something': 120,\n",
       " 'nhl': 119,\n",
       " 'must': 118,\n",
       " 'child': 118,\n",
       " 'run': 118,\n",
       " 'bite': 117,\n",
       " 'wrong': 117,\n",
       " 'isnt': 116,\n",
       " 'hell': 116,\n",
       " 'common': 116,\n",
       " 'bugatti': 116,\n",
       " 'youre': 116,\n",
       " 'severe': 116,\n",
       " 'week': 116,\n",
       " 'paint': 116,\n",
       " 'issue': 116,\n",
       " 'daughter': 116,\n",
       " 'maybe': 115,\n",
       " 'eye': 115,\n",
       " 'obamas': 115,\n",
       " 'doritosflavored': 115,\n",
       " 'best': 114,\n",
       " 'answer': 114,\n",
       " 'rinse': 113,\n",
       " 'another': 113,\n",
       " 'bad': 113,\n",
       " 'system': 112,\n",
       " 'surgery': 112,\n",
       " 'isi': 111,\n",
       " 'ban': 111,\n",
       " 'close': 111,\n",
       " 'eonline': 111,\n",
       " 'susceptible': 110,\n",
       " 'fake': 110,\n",
       " 'kid': 110,\n",
       " 'package': 110,\n",
       " 'check': 109,\n",
       " 'since': 109,\n",
       " 'he': 109,\n",
       " 'detect': 108,\n",
       " 'heart': 108,\n",
       " 'point': 108,\n",
       " 'anything': 107,\n",
       " 'video': 107,\n",
       " 'black': 107,\n",
       " 'enough': 107,\n",
       " 'ever': 107,\n",
       " 'illness': 107,\n",
       " 'today': 107,\n",
       " 'job': 106,\n",
       " 'name': 105,\n",
       " 'patient': 105,\n",
       " 'share': 105,\n",
       " 'deal': 105,\n",
       " 'nope': 105,\n",
       " 'meet': 104,\n",
       " 'data': 104,\n",
       " 'veyron': 103,\n",
       " 'travel': 103,\n",
       " 'coronaviruses': 103,\n",
       " 'start': 102,\n",
       " 'younger': 102,\n",
       " 'measure': 102,\n",
       " 'tweet': 102,\n",
       " 'reportedly': 102,\n",
       " 'manager': 102,\n",
       " 'ok': 101,\n",
       " 'every': 101,\n",
       " 'suggest': 101,\n",
       " 'trump': 101,\n",
       " 'expect': 101,\n",
       " 'letter': 101,\n",
       " 'saline': 100,\n",
       " 'already': 100,\n",
       " 'possible': 100,\n",
       " 'sneeze': 100,\n",
       " 'avoid': 100,\n",
       " 'wtf': 99,\n",
       " 'might': 99,\n",
       " 'chickfila': 99,\n",
       " 'dryer': 98,\n",
       " 'le': 98,\n",
       " 'important': 98,\n",
       " 'lie': 98,\n",
       " 'bank': 98,\n",
       " 'boob': 98,\n",
       " 'hoax': 97,\n",
       " 'ottawa': 96,\n",
       " 'yeah': 96,\n",
       " 'change': 96,\n",
       " 'era': 96,\n",
       " 'pro': 96,\n",
       " 'scanner': 95,\n",
       " 'c': 95,\n",
       " 'healthy': 95,\n",
       " 'likely': 95,\n",
       " 'study': 95,\n",
       " 'whats': 95,\n",
       " 'allow': 95,\n",
       " 'story': 95,\n",
       " 'chlorine': 94,\n",
       " 'thermal': 94,\n",
       " 'recover': 94,\n",
       " 'mh': 94,\n",
       " 'understand': 94,\n",
       " 'soap': 94,\n",
       " 'claim': 94,\n",
       " 'cnn': 94,\n",
       " 'star': 94,\n",
       " 'drink': 93,\n",
       " 'face': 93,\n",
       " 'money': 93,\n",
       " 'temperature': 92,\n",
       " 'guess': 92,\n",
       " 'soon': 92,\n",
       " 'b': 92,\n",
       " 'high': 92,\n",
       " 'old': 92,\n",
       " 'pet': 92,\n",
       " 'tshirt': 92,\n",
       " 'send': 91,\n",
       " 'actually': 91,\n",
       " 'furious': 91,\n",
       " 'far': 90,\n",
       " 'free': 90,\n",
       " 'away': 90,\n",
       " 'arrest': 90,\n",
       " 'gun': 90,\n",
       " 'wonder': 89,\n",
       " 'medium': 89,\n",
       " 'national': 89,\n",
       " 'buster': 89,\n",
       " 'nothing': 88,\n",
       " 'tv': 88,\n",
       " 'jail': 88,\n",
       " 'corona': 87,\n",
       " 'lot': 87,\n",
       " 'reason': 87,\n",
       " 'network': 86,\n",
       " 'suspect': 86,\n",
       " 'memorial': 86,\n",
       " 'least': 86,\n",
       " 'via': 86,\n",
       " 'rest': 86,\n",
       " 'mosquito': 85,\n",
       " 'higher': 85,\n",
       " 'there': 85,\n",
       " 'social': 85,\n",
       " 'mild': 85,\n",
       " 'anyone': 84,\n",
       " 'miss': 84,\n",
       " 'cover': 84,\n",
       " 'puppy': 84,\n",
       " 'humid': 83,\n",
       " 'difficulty': 83,\n",
       " 'situation': 83,\n",
       " 'different': 83,\n",
       " 'th': 83,\n",
       " 'light': 83,\n",
       " 'hour': 83,\n",
       " 'climate': 82,\n",
       " 'release': 82,\n",
       " 'play': 82,\n",
       " 'bring': 82,\n",
       " 'deer': 82,\n",
       " 'hank': 82,\n",
       " 'xxl': 82,\n",
       " 'bath': 81,\n",
       " 'hold': 81,\n",
       " 'control': 81,\n",
       " 'end': 81,\n",
       " 'size': 81,\n",
       " 'exactly': 81,\n",
       " 'goliath': 81,\n",
       " 'condition': 80,\n",
       " 'pandemic': 80,\n",
       " 'friend': 80,\n",
       " 'rate': 80,\n",
       " 'plus': 79,\n",
       " 'support': 79,\n",
       " 'idea': 79,\n",
       " 'canadian': 78,\n",
       " 'plan': 78,\n",
       " 'low': 78,\n",
       " 'distance': 78,\n",
       " 'open': 78,\n",
       " 'fall': 78,\n",
       " 'official': 78,\n",
       " 'banksy': 78,\n",
       " 'frediboat': 78,\n",
       " 'probably': 77,\n",
       " 'save': 77,\n",
       " 'school': 77,\n",
       " 'positive': 77,\n",
       " 'ive': 77,\n",
       " 'taste': 77,\n",
       " 'lose': 76,\n",
       " 'gang': 76,\n",
       " 'though': 76,\n",
       " 'sars': 76,\n",
       " 'phone': 76,\n",
       " 'wait': 76,\n",
       " 'recommend': 76,\n",
       " 'stupid': 76,\n",
       " 'usa': 75,\n",
       " 'next': 75,\n",
       " 'r': 75,\n",
       " 'wasnt': 75,\n",
       " 'lego': 75,\n",
       " 'lamp': 74,\n",
       " 'everything': 74,\n",
       " 'link': 74,\n",
       " 'louisiana': 74,\n",
       " 'survive': 73,\n",
       " 'sweet': 73,\n",
       " 'starbucks': 73,\n",
       " 'gay': 73,\n",
       " 'move': 72,\n",
       " 'damn': 72,\n",
       " 'canada': 72,\n",
       " 'little': 72,\n",
       " 'twerking': 72,\n",
       " 'website': 71,\n",
       " 'pope': 71,\n",
       " 'serious': 70,\n",
       " 'factcheck': 70,\n",
       " 'birdeater': 70,\n",
       " 'mobile': 69,\n",
       " 'build': 69,\n",
       " 'month': 69,\n",
       " 'fight': 69,\n",
       " 'learn': 69,\n",
       " 'fire': 69,\n",
       " 'yall': 69,\n",
       " 'slang': 69,\n",
       " 'discover': 68,\n",
       " 'ferguson': 68,\n",
       " 'small': 68,\n",
       " 'novel': 68,\n",
       " 'sound': 68,\n",
       " 'employee': 68,\n",
       " 'reality': 68,\n",
       " 'lord': 68,\n",
       " 'attack': 67,\n",
       " 'law': 67,\n",
       " 'x': 67,\n",
       " 'order': 67,\n",
       " 'continue': 67,\n",
       " 'post': 67,\n",
       " 'id': 67,\n",
       " 'sugarhill': 67,\n",
       " 'able': 66,\n",
       " 'girl': 66,\n",
       " 'muslim': 66,\n",
       " 'hospital': 66,\n",
       " 'peace': 66,\n",
       " 'parent': 66,\n",
       " 'mt': 66,\n",
       " 'de': 66,\n",
       " 'dangerous': 65,\n",
       " 'n': 65,\n",
       " 'begin': 65,\n",
       " 'several': 65,\n",
       " 'rather': 65,\n",
       " 'always': 65,\n",
       " 'large': 65,\n",
       " 'current': 65,\n",
       " 'provide': 65,\n",
       " 'pepsi': 65,\n",
       " 'whole': 64,\n",
       " 'car': 64,\n",
       " 'base': 64,\n",
       " 'remember': 64,\n",
       " 'alive': 64,\n",
       " 'breast': 64,\n",
       " 'guinness': 64,\n",
       " 'mashable': 63,\n",
       " 'crazy': 63,\n",
       " 'blood': 63,\n",
       " 'experience': 63,\n",
       " 'early': 63,\n",
       " 'simple': 63,\n",
       " 'owner': 63,\n",
       " 'population': 63,\n",
       " 'kind': 63,\n",
       " 'hello': 63,\n",
       " 'hard': 63,\n",
       " 'antibody': 63,\n",
       " 'research': 62,\n",
       " 'uk': 62,\n",
       " 'movie': 62,\n",
       " 'surgically': 62,\n",
       " 'latte': 62,\n",
       " 'expose': 61,\n",
       " 'w': 61,\n",
       " 'wuhan': 61,\n",
       " 'frequently': 61,\n",
       " 'member': 61,\n",
       " 'rainbow': 61,\n",
       " 'fakenews': 61,\n",
       " 'interest': 60,\n",
       " 'appear': 60,\n",
       " 'worry': 60,\n",
       " 'foxnews': 60,\n",
       " 'e': 60,\n",
       " 'speak': 60,\n",
       " 'transmission': 60,\n",
       " 'night': 60,\n",
       " 'example': 59,\n",
       " 'diabetes': 59,\n",
       " 'seriously': 59,\n",
       " 'vote': 59,\n",
       " 'lockdown': 59,\n",
       " 'list': 59,\n",
       " 'step': 59,\n",
       " 'book': 59,\n",
       " 'omg': 59,\n",
       " 'paris': 59,\n",
       " 'k': 59,\n",
       " 'bid': 59,\n",
       " 'second': 58,\n",
       " 'advice': 58,\n",
       " 'funny': 58,\n",
       " 'hey': 58,\n",
       " 'hi': 58,\n",
       " 'turn': 58,\n",
       " 'seek': 58,\n",
       " 'individual': 58,\n",
       " 'terrorist': 57,\n",
       " 'act': 57,\n",
       " 'reduce': 57,\n",
       " 'theyre': 57,\n",
       " 'especially': 57,\n",
       " 'article': 57,\n",
       " 'saw': 57,\n",
       " 'info': 57,\n",
       " 'toronto': 57,\n",
       " 'sense': 56,\n",
       " 'poor': 56,\n",
       " 'object': 56,\n",
       " 'protection': 56,\n",
       " 'parliament': 56,\n",
       " 'happy': 56,\n",
       " 'ppl': 56,\n",
       " 'worker': 56,\n",
       " 'fanged': 56,\n",
       " 'fxnscitech': 56,\n",
       " 'snow': 55,\n",
       " 'shooter': 55,\n",
       " 'mass': 55,\n",
       " 'authority': 55,\n",
       " 'head': 55,\n",
       " 'etc': 55,\n",
       " 'period': 55,\n",
       " 'gunman': 55,\n",
       " 'sorry': 54,\n",
       " 'course': 54,\n",
       " 'type': 54,\n",
       " 'alcoholbased': 54,\n",
       " 'sit': 54,\n",
       " 'agree': 54,\n",
       " 'full': 54,\n",
       " 'hate': 54,\n",
       " 'enter': 54,\n",
       " 'fear': 54,\n",
       " 'ago': 54,\n",
       " 'seattle': 54,\n",
       " 'doctor': 53,\n",
       " 'drug': 53,\n",
       " 'available': 53,\n",
       " 'increase': 53,\n",
       " 'gonna': 53,\n",
       " 'total': 53,\n",
       " 'recall': 53,\n",
       " 'joke': 53,\n",
       " 'matter': 53,\n",
       " 'influenza': 53,\n",
       " 'charlie': 52,\n",
       " 'victim': 52,\n",
       " 'action': 52,\n",
       " 'instead': 52,\n",
       " 'cop': 52,\n",
       " 'color': 52,\n",
       " 'therefore': 52,\n",
       " 'shut': 52,\n",
       " 'cure': 52,\n",
       " 'remain': 52,\n",
       " 'prayer': 52,\n",
       " 'delay': 52,\n",
       " 'sydney': 52,\n",
       " 'passenger': 52,\n",
       " 'abandon': 52,\n",
       " 'behead': 51,\n",
       " 'record': 51,\n",
       " 'foot': 51,\n",
       " 'independent': 51,\n",
       " 'local': 51,\n",
       " 'rule': 51,\n",
       " 'young': 51,\n",
       " 'expert': 51,\n",
       " 'highly': 51,\n",
       " 'airborne': 51,\n",
       " 'pop': 51,\n",
       " 'disinfection': 50,\n",
       " 'plane': 50,\n",
       " 'listen': 50,\n",
       " 'range': 50,\n",
       " 'rub': 50,\n",
       " 'evil': 50,\n",
       " 'present': 50,\n",
       " 'group': 50,\n",
       " 'belong': 50,\n",
       " 'burgerking': 50,\n",
       " 'hebdo': 49,\n",
       " 'nice': 49,\n",
       " 'pregnant': 49,\n",
       " 'mind': 49,\n",
       " 'party': 49,\n",
       " 'visit': 49,\n",
       " 'disgust': 49,\n",
       " 'fee': 49,\n",
       " 'immune': 49,\n",
       " 'hit': 49,\n",
       " 'punishment': 49,\n",
       " 'set': 49,\n",
       " 'adopt': 49,\n",
       " 'scrap': 49,\n",
       " 'nurse': 49,\n",
       " 'dailymail': 49,\n",
       " 'ultraviolet': 48,\n",
       " 'p': 48,\n",
       " 'arent': 48,\n",
       " 'dry': 48,\n",
       " 'rat': 48,\n",
       " 'advise': 48,\n",
       " 'que': 48,\n",
       " 'else': 48,\n",
       " 'truth': 48,\n",
       " 'contaminate': 48,\n",
       " 'idiot': 48,\n",
       " 'walk': 48,\n",
       " 'sign': 48,\n",
       " 'v': 47,\n",
       " 'false': 47,\n",
       " 'latest': 47,\n",
       " 'pretty': 47,\n",
       " 'prevention': 47,\n",
       " 'community': 47,\n",
       " 'wouldnt': 47,\n",
       " 'per': 47,\n",
       " 'poll': 47,\n",
       " 'govt': 47,\n",
       " 'illegal': 47,\n",
       " 'tragic': 46,\n",
       " 'contract': 46,\n",
       " 'david': 46,\n",
       " 'science': 46,\n",
       " 'due': 46,\n",
       " 'powerful': 46,\n",
       " 'pourmecoffee': 46,\n",
       " 'ya': 45,\n",
       " 'concern': 45,\n",
       " 'paper': 45,\n",
       " 'consider': 45,\n",
       " 'tissue': 45,\n",
       " 'create': 45,\n",
       " 'wish': 45,\n",
       " 'boy': 45,\n",
       " 'normal': 45,\n",
       " 'bacteria': 45,\n",
       " 'regardless': 45,\n",
       " 'near': 44,\n",
       " 'explain': 44,\n",
       " 'italy': 44,\n",
       " 'organization': 44,\n",
       " 'worst': 44,\n",
       " 'exist': 44,\n",
       " 'force': 44,\n",
       " 'choose': 44,\n",
       " 'twitter': 44,\n",
       " 'station': 44,\n",
       " 'crash': 44,\n",
       " 'chocolate': 44,\n",
       " 'picture': 44,\n",
       " 'radioactive': 44,\n",
       " 'impose': 44,\n",
       " 'ha': 43,\n",
       " 'sun': 43,\n",
       " 'charliehebdo': 43,\n",
       " 'shouldnt': 43,\n",
       " 'mainly': 43,\n",
       " 'leader': 43,\n",
       " 'trust': 43,\n",
       " 'havent': 43,\n",
       " 'kkk': 43,\n",
       " 'fukushima': 43,\n",
       " 'huffingtonpost': 43,\n",
       " 'three': 42,\n",
       " 'putin': 42,\n",
       " 'offer': 42,\n",
       " 'previous': 42,\n",
       " 'immediately': 42,\n",
       " 'chance': 42,\n",
       " 'company': 42,\n",
       " 'stand': 42,\n",
       " 'cut': 42,\n",
       " 'shame': 42,\n",
       " 'beautiful': 42,\n",
       " 'decision': 42,\n",
       " 'draw': 42,\n",
       " 'train': 42,\n",
       " 'pumpkin': 42,\n",
       " 'ibuprofen': 42,\n",
       " 'breath': 41,\n",
       " 'behind': 41,\n",
       " 'outside': 41,\n",
       " 'lead': 41,\n",
       " 'exhale': 41,\n",
       " 'usually': 41,\n",
       " 'mention': 41,\n",
       " 'interview': 41,\n",
       " 'prove': 41,\n",
       " 'el': 41,\n",
       " 'meat': 41,\n",
       " 'estimate': 41,\n",
       " 'top': 41,\n",
       " 'attention': 41,\n",
       " 'shes': 41,\n",
       " 'mom': 41,\n",
       " 'foxphilly': 41,\n",
       " 'offense': 41,\n",
       " 'driver': 40,\n",
       " 'smh': 40,\n",
       " 'di': 40,\n",
       " 'pick': 40,\n",
       " 'business': 40,\n",
       " 'main': 40,\n",
       " 'site': 40,\n",
       " 'lung': 40,\n",
       " 'limit': 40,\n",
       " 'pm': 40,\n",
       " 'declare': 40,\n",
       " 'tax': 40,\n",
       " 'physical': 40,\n",
       " 'sell': 40,\n",
       " 'hill': 40,\n",
       " 'thread': 40,\n",
       " 'response': 40,\n",
       " 'clear': 40,\n",
       " 'yr': 40,\n",
       " 'condom': 40,\n",
       " 'leak': 40,\n",
       " 'fakebuster': 40,\n",
       " 'katrinalome': 40,\n",
       " 'lmao': 39,\n",
       " 'infectious': 39,\n",
       " 'murder': 39,\n",
       " 'worse': 39,\n",
       " 'either': 39,\n",
       " 'together': 39,\n",
       " 'finally': 39,\n",
       " 'cat': 39,\n",
       " 'aint': 39,\n",
       " 'message': 39,\n",
       " 'skin': 39,\n",
       " 'harry': 39,\n",
       " 'level': 38,\n",
       " 'charge': 38,\n",
       " 'accord': 38,\n",
       " 'daily': 38,\n",
       " 'syndrome': 38,\n",
       " 'contain': 38,\n",
       " 'game': 38,\n",
       " 'throw': 38,\n",
       " 'speed': 38,\n",
       " 'dear': 38,\n",
       " 'quickly': 38,\n",
       " 'destroy': 38,\n",
       " 'sir': 38,\n",
       " 'currently': 38,\n",
       " 'late': 38,\n",
       " 'grow': 38,\n",
       " 'burn': 38,\n",
       " 'bet': 37,\n",
       " 'rid': 37,\n",
       " 'preexist': 37,\n",
       " 'knowthefacts': 37,\n",
       " 'practice': 37,\n",
       " 'alone': 37,\n",
       " 'variety': 37,\n",
       " 'cancer': 37,\n",
       " 'spice': 37,\n",
       " 'stephen': 37,\n",
       " 'chinese': 36,\n",
       " 'breakfast': 36,\n",
       " 'inside': 36,\n",
       " 'ur': 36,\n",
       " 'forget': 36,\n",
       " 'throat': 36,\n",
       " 'da': 36,\n",
       " 'slow': 36,\n",
       " 'oil': 36,\n",
       " 'dude': 36,\n",
       " 'st': 36,\n",
       " 'harmful': 36,\n",
       " 'whether': 36,\n",
       " 'scar': 36,\n",
       " 'negative': 36,\n",
       " 'hop': 36,\n",
       " 'glove': 36,\n",
       " 'men': 36,\n",
       " 'red': 36,\n",
       " 'tmz': 36,\n",
       " 'wake': 36,\n",
       " 'mandatory': 36,\n",
       " 'nigeria': 36,\n",
       " 'bestpronews': 36,\n",
       " 'minister': 35,\n",
       " 'comment': 35,\n",
       " 'choice': 35,\n",
       " 'land': 35,\n",
       " 'history': 35,\n",
       " 'recently': 35,\n",
       " 'ongoing': 35,\n",
       " 'uv': 35,\n",
       " 'ie': 35,\n",
       " 'stuff': 35,\n",
       " 'king': 35,\n",
       " 'effect': 35,\n",
       " 'require': 35,\n",
       " 'win': 35,\n",
       " 'amaze': 35,\n",
       " 'asymptomatic': 35,\n",
       " 'racist': 35,\n",
       " 'shot': 35,\n",
       " 'gt': 35,\n",
       " 'fail': 35,\n",
       " 'refugee': 35,\n",
       " 'marlboro': 35,\n",
       " 'ocean': 35,\n",
       " 'suitcase': 35,\n",
       " 'flag': 34,\n",
       " 'cdc': 34,\n",
       " 'trial': 34,\n",
       " 'bless': 34,\n",
       " 'baby': 34,\n",
       " 'meter': 34,\n",
       " 'bear': 34,\n",
       " 'global': 34,\n",
       " 'mers': 34,\n",
       " 'aware': 34,\n",
       " 'thought': 34,\n",
       " 'military': 34,\n",
       " 'warn': 34,\n",
       " 'later': 34,\n",
       " 'return': 34,\n",
       " 'weve': 34,\n",
       " 'store': 34,\n",
       " 'grocery': 34,\n",
       " 'market': 34,\n",
       " 'dr': 34,\n",
       " 'proof': 34,\n",
       " 'healthcare': 34,\n",
       " 'nestl': 34,\n",
       " 'burger': 34,\n",
       " 'dewitos': 34,\n",
       " 'facility': 34,\n",
       " 'durex': 34,\n",
       " 'boko': 34,\n",
       " 'sleep': 33,\n",
       " 'race': 33,\n",
       " 'runny': 33,\n",
       " 'pressure': 33,\n",
       " 'identify': 33,\n",
       " 'unwell': 33,\n",
       " 'special': 33,\n",
       " 'thoroughly': 33,\n",
       " 'bacterial': 33,\n",
       " 'sarscov': 33,\n",
       " 'direct': 33,\n",
       " 'absolutely': 33,\n",
       " 'ebola': 33,\n",
       " 'newcrownvirus': 33,\n",
       " 'monday': 33,\n",
       " 'cafe': 33,\n",
       " 'four': 33,\n",
       " 'january': 33,\n",
       " 'uberfacts': 33,\n",
       " 'jamie': 33,\n",
       " 'experiment': 33,\n",
       " 'haram': 33,\n",
       " 'sydneysiege': 32,\n",
       " 'middle': 32,\n",
       " 'dumb': 32,\n",
       " 'prepare': 32,\n",
       " 'haines': 32,\n",
       " 'cool': 32,\n",
       " 'feature': 32,\n",
       " 'en': 32,\n",
       " 'correct': 32,\n",
       " 'holy': 32,\n",
       " 'fill': 32,\n",
       " 'detail': 32,\n",
       " 'inform': 32,\n",
       " 'vulnerable': 32,\n",
       " 'view': 32,\n",
       " 'symptomatic': 32,\n",
       " 'ukraine': 32,\n",
       " 'internet': 32,\n",
       " 'plant': 32,\n",
       " 'grey': 32,\n",
       " 'hip': 32,\n",
       " 'nd': 31,\n",
       " 'terrible': 31,\n",
       " 'non': 31,\n",
       " 'citizen': 31,\n",
       " 'side': 31,\n",
       " 'officer': 31,\n",
       " 'sore': 31,\n",
       " 'service': 31,\n",
       " 'smoke': 31,\n",
       " 'pas': 31,\n",
       " 'power': 31,\n",
       " 'heaven': 31,\n",
       " 'property': 31,\n",
       " 'marriage': 31,\n",
       " 'couldnt': 31,\n",
       " 'bruh': 31,\n",
       " 'similar': 31,\n",
       " 'block': 31,\n",
       " 'billion': 31,\n",
       " 'emergency': 31,\n",
       " 'malaysia': 31,\n",
       " 'event': 31,\n",
       " 'value': 31,\n",
       " 'compare': 31,\n",
       " 'appearance': 31,\n",
       " 'beer': 31,\n",
       " 'international': 31,\n",
       " 'potter': 31,\n",
       " 'shade': 31,\n",
       " 'reaitupac': 31,\n",
       " 'dispose': 30,\n",
       " 'statement': 30,\n",
       " 'missile': 30,\n",
       " 'difference': 30,\n",
       " 'completely': 30,\n",
       " 'shutdown': 30,\n",
       " 'suppose': 30,\n",
       " 'economy': 30,\n",
       " ...}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tokens(df):\n",
    "    token_counts = {}\n",
    "    for token_list in list(df['tokens']):\n",
    "        for token in token_list:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "    return {k: v for k, v in sorted(token_counts.items(), key=lambda item: item[1],reverse=True)}\n",
    "            \n",
    "unigram_counts = count_tokens(train_full_df)\n",
    "unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "adc90e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = {}\n",
    "repeat_users = []\n",
    "\n",
    "for user in train_full_df['user']:\n",
    "    if user == 'mashable':\n",
    "        if 'u_mashable' in user_counts:\n",
    "            user_counts['u_mashable'] +=1\n",
    "        else:\n",
    "            user_counts['u_mashable'] = 1\n",
    "    elif user in user_counts:\n",
    "        user_counts[user] +=1\n",
    "    else:\n",
    "        user_counts[user] = 1\n",
    "        \n",
    "for k, v in user_counts.items():\n",
    "    if v > 1:\n",
    "        repeat_users.append(k)\n",
    "        \n",
    "repeat_users\n",
    "\n",
    "def top_users(df, repeat_users):\n",
    "    df_new = df\n",
    "    df_new = df_new.reindex(columns = list(df_new.columns) + repeat_users, fill_value = 0)\n",
    "    for i, row in df_new.iterrows():\n",
    "        if row['user'] == 'mashable':\n",
    "            df_new.at[i, 'u_mashable'] = 1\n",
    "        elif row['user'] in repeat_users:\n",
    "            df_new.at[i, row['user']] = 1\n",
    "    df_new.drop(['user'],axis=1,inplace=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7bb20072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>...</th>\n",
       "      <th>employee</th>\n",
       "      <th>reality</th>\n",
       "      <th>lord</th>\n",
       "      <th>attack</th>\n",
       "      <th>law</th>\n",
       "      <th>x</th>\n",
       "      <th>order</th>\n",
       "      <th>continue</th>\n",
       "      <th>post</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.173437</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278125</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.040770</td>\n",
       "      <td>sattykrosse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>-0.191270</td>\n",
       "      <td>Bipartisanism</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.031427</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>-0.057692</td>\n",
       "      <td>NBCNews</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>-0.005323</td>\n",
       "      <td>rosierawle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment             user  verified  likes  retweets  covid  \\\n",
       "0      0.173437        ucoptempe         0      0         0      1   \n",
       "1     -0.278125        Telegraph         1     43       184      0   \n",
       "2      0.133333  kareem_alnakeeb         0      4         1      1   \n",
       "3      0.133333              WSJ         1     23       120      0   \n",
       "4      0.400000     hoss_bossman         0      6         1      0   \n",
       "...         ...              ...       ...    ...       ...    ...   \n",
       "1560   0.040770      sattykrosse         0      0         0      1   \n",
       "1561  -0.191270    Bipartisanism         1     56        76      0   \n",
       "1562   0.031427              ABC         1    148       108      0   \n",
       "1563  -0.057692          NBCNews         1     63       176      0   \n",
       "1564  -0.005323       rosierawle         0      0         0      0   \n",
       "\n",
       "      coronavirus  people  new  virus  ...  employee  reality  lord  attack  \\\n",
       "0               1       1    1      1  ...         0        0     0       0   \n",
       "1               0       0    0      0  ...         0        0     0       1   \n",
       "2               1       0    0      0  ...         0        0     0       0   \n",
       "3               0       1    0      0  ...         0        0     0       1   \n",
       "4               0       0    0      0  ...         0        0     0       0   \n",
       "...           ...     ...  ...    ...  ...       ...      ...   ...     ...   \n",
       "1560            1       1    1      1  ...         0        0     0       0   \n",
       "1561            0       0    0      0  ...         0        0     0       0   \n",
       "1562            0       0    1      0  ...         0        0     0       0   \n",
       "1563            0       0    0      0  ...         0        0     0       0   \n",
       "1564            0       0    1      0  ...         0        0     0       0   \n",
       "\n",
       "      law  x  order  continue  post  id  \n",
       "0       0  0      0         0     0   0  \n",
       "1       0  0      0         0     0   0  \n",
       "2       0  0      0         0     0   0  \n",
       "3       0  0      0         0     0   0  \n",
       "4       0  0      0         0     0   0  \n",
       "...   ... ..    ...       ...   ...  ..  \n",
       "1560    0  0      0         0     0   0  \n",
       "1561    0  0      0         0     0   0  \n",
       "1562    1  0      0         0     0   0  \n",
       "1563    0  0      0         0     0   0  \n",
       "1564    0  0      0         0     0   0  \n",
       "\n",
       "[1553 rows x 505 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_n(df, n):\n",
    "    return list(df.columns)+list(unigram_counts.keys())[0:n]\n",
    "\n",
    "def df_top_tokens(df, cols):\n",
    "    df_new = df\n",
    "    df_new = df_new.reindex(columns=cols, fill_value=0)\n",
    "    for i, row in df_new.iterrows():\n",
    "        for token in row['tokens']:\n",
    "            if token in list(df_new.columns):\n",
    "                df_new.at[i, token] = 1\n",
    "    df_new.drop(['tokens'],axis=1,inplace=True)\n",
    "    return df_new\n",
    "\n",
    "y_train = train_full_df['label']\n",
    "y_dev = dev_full_df['label']\n",
    "\n",
    "train_full_df.drop('label',axis=1,inplace=True)\n",
    "dev_full_df.drop('label',axis=1,inplace=True)\n",
    "\n",
    "cols_500 = top_n(train_full_df, 500)\n",
    "cols_1000 = top_n(train_full_df, 1000)\n",
    "\n",
    "train_df_500 = df_top_tokens(train_full_df, cols_500)\n",
    "dev_df_500 = df_top_tokens(dev_full_df, cols_500)\n",
    "test_df_500 = df_top_tokens(test_full_df, cols_500)\n",
    "\n",
    "train_df_1000 = df_top_tokens(train_full_df, cols_1000)\n",
    "dev_df_1000 = df_top_tokens(dev_full_df, cols_1000)\n",
    "test_df_1000 = df_top_tokens(test_full_df, cols_1000)\n",
    "\n",
    "train_df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a07e7f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>Netcare911_sa</th>\n",
       "      <th>ExpediteLlp</th>\n",
       "      <th>OpenParlyZw</th>\n",
       "      <th>washingtonpost</th>\n",
       "      <th>SenatorBiaggi</th>\n",
       "      <th>PennsylvaniaDEP</th>\n",
       "      <th>Jinxie_Al</th>\n",
       "      <th>MANASA96592377</th>\n",
       "      <th>cahwerneck</th>\n",
       "      <th>COVIDNewsByMIB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows × 1162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment  verified     likes  retweets  covid  coronavirus  people  \\\n",
       "0      0.586719         0  0.000000  0.000000      1            1       1   \n",
       "1      0.360938         1  0.005440  0.026096      0            0       0   \n",
       "2      0.566667         0  0.000506  0.000142      1            1       0   \n",
       "3      0.566667         1  0.002910  0.017019      0            0       1   \n",
       "4      0.700000         0  0.000759  0.000142      0            0       0   \n",
       "...         ...       ...       ...       ...    ...          ...     ...   \n",
       "1560   0.520385         0  0.000000  0.000000      1            1       1   \n",
       "1561   0.404365         1  0.007085  0.010779      0            0       0   \n",
       "1562   0.515714         1  0.018725  0.015317      0            0       0   \n",
       "1563   0.471154         1  0.007971  0.024961      0            0       0   \n",
       "1564   0.497339         0  0.000000  0.000000      0            0       0   \n",
       "\n",
       "      new  virus  get  ...  Netcare911_sa  ExpediteLlp  OpenParlyZw  \\\n",
       "0       1      1    0  ...              0            0            0   \n",
       "1       0      0    1  ...              0            0            0   \n",
       "2       0      0    0  ...              0            0            0   \n",
       "3       0      0    0  ...              0            0            0   \n",
       "4       0      0    0  ...              0            0            0   \n",
       "...   ...    ...  ...  ...            ...          ...          ...   \n",
       "1560    1      1    0  ...              0            0            0   \n",
       "1561    0      0    1  ...              0            0            0   \n",
       "1562    1      0    1  ...              0            0            0   \n",
       "1563    0      0    0  ...              0            0            0   \n",
       "1564    1      0    0  ...              0            0            0   \n",
       "\n",
       "      washingtonpost  SenatorBiaggi  PennsylvaniaDEP  Jinxie_Al  \\\n",
       "0                  0              0                0          0   \n",
       "1                  0              0                0          0   \n",
       "2                  0              0                0          0   \n",
       "3                  0              0                0          0   \n",
       "4                  0              0                0          0   \n",
       "...              ...            ...              ...        ...   \n",
       "1560               0              0                0          0   \n",
       "1561               0              0                0          0   \n",
       "1562               0              0                0          0   \n",
       "1563               0              0                0          0   \n",
       "1564               0              0                0          0   \n",
       "\n",
       "      MANASA96592377  cahwerneck  COVIDNewsByMIB  \n",
       "0                  0           0               0  \n",
       "1                  0           0               0  \n",
       "2                  0           0               0  \n",
       "3                  0           0               0  \n",
       "4                  0           0               0  \n",
       "...              ...         ...             ...  \n",
       "1560               0           0               0  \n",
       "1561               0           0               0  \n",
       "1562               0           0               0  \n",
       "1563               0           0               0  \n",
       "1564               0           0               0  \n",
       "\n",
       "[1553 rows x 1162 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df_500_users = top_users(train_df_500, repeat_users)\n",
    "#train_df_1000_users = top_users(train_df_1000, repeat_users)\n",
    "train_df_1000_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b4835ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>user</th>\n",
       "      <th>verified</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>covid</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>people</th>\n",
       "      <th>new</th>\n",
       "      <th>virus</th>\n",
       "      <th>...</th>\n",
       "      <th>employee</th>\n",
       "      <th>reality</th>\n",
       "      <th>lord</th>\n",
       "      <th>attack</th>\n",
       "      <th>law</th>\n",
       "      <th>x</th>\n",
       "      <th>order</th>\n",
       "      <th>continue</th>\n",
       "      <th>post</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586719</td>\n",
       "      <td>ucoptempe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360938</td>\n",
       "      <td>Telegraph</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>kareem_alnakeeb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>hoss_bossman</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0.520385</td>\n",
       "      <td>sattykrosse</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>0.404365</td>\n",
       "      <td>Bipartisanism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007085</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.471154</td>\n",
       "      <td>NBCNews</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>0.497339</td>\n",
       "      <td>rosierawle</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1553 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment             user  verified     likes  retweets  covid  \\\n",
       "0      0.586719        ucoptempe         0  0.000000  0.000000      1   \n",
       "1      0.360938        Telegraph         1  0.005440  0.026096      0   \n",
       "2      0.566667  kareem_alnakeeb         0  0.000506  0.000142      1   \n",
       "3      0.566667              WSJ         1  0.002910  0.017019      0   \n",
       "4      0.700000     hoss_bossman         0  0.000759  0.000142      0   \n",
       "...         ...              ...       ...       ...       ...    ...   \n",
       "1560   0.520385      sattykrosse         0  0.000000  0.000000      1   \n",
       "1561   0.404365    Bipartisanism         1  0.007085  0.010779      0   \n",
       "1562   0.515714              ABC         1  0.018725  0.015317      0   \n",
       "1563   0.471154          NBCNews         1  0.007971  0.024961      0   \n",
       "1564   0.497339       rosierawle         0  0.000000  0.000000      0   \n",
       "\n",
       "      coronavirus  people  new  virus  ...  employee  reality  lord  attack  \\\n",
       "0               1       1    1      1  ...         0        0     0       0   \n",
       "1               0       0    0      0  ...         0        0     0       1   \n",
       "2               1       0    0      0  ...         0        0     0       0   \n",
       "3               0       1    0      0  ...         0        0     0       1   \n",
       "4               0       0    0      0  ...         0        0     0       0   \n",
       "...           ...     ...  ...    ...  ...       ...      ...   ...     ...   \n",
       "1560            1       1    1      1  ...         0        0     0       0   \n",
       "1561            0       0    0      0  ...         0        0     0       0   \n",
       "1562            0       0    1      0  ...         0        0     0       0   \n",
       "1563            0       0    0      0  ...         0        0     0       0   \n",
       "1564            0       0    1      0  ...         0        0     0       0   \n",
       "\n",
       "      law  x  order  continue  post  id  \n",
       "0       0  0      0         0     0   0  \n",
       "1       0  0      0         0     0   0  \n",
       "2       0  0      0         0     0   0  \n",
       "3       0  0      0         0     0   0  \n",
       "4       0  0      0         0     0   0  \n",
       "...   ... ..    ...       ...   ...  ..  \n",
       "1560    0  0      0         0     0   0  \n",
       "1561    0  0      0         0     0   0  \n",
       "1562    1  0      0         0     0   0  \n",
       "1563    0  0      0         0     0   0  \n",
       "1564    0  0      0         0     0   0  \n",
       "\n",
       "[1553 rows x 505 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def scale_df(train, dev, test):\n",
    "    train_scaled = train\n",
    "    dev_scaled = dev\n",
    "    test_scaled = test\n",
    "    for col in ['sentiment','retweets','likes']:\n",
    "        if col in list(train_scaled.columns):\n",
    "            sc = MinMaxScaler().fit(train_scaled[col].values.reshape(-1,1))\n",
    "            train_scaled[col] = sc.transform(train_scaled[col].values.reshape(-1,1))\n",
    "            dev_scaled[col] = sc.transform(dev_scaled[col].values.reshape(-1,1))\n",
    "            test_scaled[col] = sc.transform(test_scaled[col].values.reshape(-1,1))\n",
    "    return train_scaled, dev_scaled, test_scaled\n",
    "\n",
    "train_df_500, dev_df_500, test_df_500 = scale_df(train_df_500, dev_df_500, test_df_500)\n",
    "train_df_1000, dev_df_1000, test_df_1000 = scale_df(train_df_1000, dev_df_1000, test_df_1000)\n",
    "train_df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a99f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model_500 = Sequential()\n",
    "model_500.add(Dense(502, activation='relu', input_shape=(502,)))\n",
    "model_500.add(Dropout(0.2))\n",
    "model_500.add(Dense(128, activation='relu'))\n",
    "model_500.add(Dropout(0.2))\n",
    "model_500.add(Dense(64, activation='relu'))\n",
    "model_500.add(Dropout(0.2))\n",
    "model_500.add(Dense(1, activation='sigmoid'))\n",
    "model_500.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model_500.fit(train_df_500, y_train, validation_data=(dev_df_500, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
    "\n",
    "_, train_acc = model_500.evaluate(train_df_500, y_train, verbose=0)\n",
    "_, test_acc = model_500.evaluate(dev_df_500, y_dev, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1000 = Sequential()\n",
    "model_1000.add(Dense(1002, activation='relu', input_shape=(1002,)))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(512, activation='relu'))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(128, activation='relu'))\n",
    "model_1000.add(Dropout(0.2))\n",
    "model_1000.add(Dense(1, activation='sigmoid'))\n",
    "model_1000.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model_1000.fit(train_df_1000, y_train, validation_data=(dev_df_1000, y_dev), epochs=4000, verbose=1, callbacks=[es])\n",
    "\n",
    "_, train_acc = model_1000.evaluate(train_df_1000, y_train, verbose=0)\n",
    "_, test_acc = model_1000.evaluate(dev_df_1000, y_dev, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "predictions_500 = [convert_to_binary(y) for y in model_500.predict(test_df_500)]\n",
    "predictions_1000 = [convert_to_binary(y) for y in model_1000.predict(test_df_1000)]\n",
    "\n",
    "predictions_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658dcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(predictions_500)):\n",
    "    if predictions_500[i] == predictions_1000[i]:\n",
    "        count+=1\n",
    "        \n",
    "count/len(predictions_500)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "output_filename = 'nn_predictions_2000.csv'\n",
    "\n",
    "header = ['Id', 'Predicted']\n",
    "with open(output_filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    for i, pred in enumerate(predictions_2000):\n",
    "        data = [str(i), str(pred)]\n",
    "        writer.writerow(data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
